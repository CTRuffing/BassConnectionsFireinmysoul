{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07b93264",
   "metadata": {},
   "source": [
    "Generates Voronoi Figures (don't have to run, I already uploaded the output to this part above, just go to the second code chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a78d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "src = r\"C:\\Users\\ctr22\\Downloads\\gadm41_PSE_1.json\\gadm41_PSE_1.json\"  # your path\n",
    "\n",
    "gdf = gpd.read_file(src)\n",
    "print(\"CRS:\", gdf.crs)\n",
    "print(\"Number of features:\", len(gdf))\n",
    "print(\"\\nColumns:\\n\", list(gdf.columns))\n",
    "print(\"\\nFirst rows:\")\n",
    "display(gdf.head())\n",
    "\n",
    "\n",
    "# Try common name columns and show unique values (limit)\n",
    "candidates = [\"NAME_0\",\"NAME_1\",\"NAME\",\"GID_0\",\"GID_1\",\"VARNAME_1\",\"ENGTYPE_1\"]\n",
    "found = {}\n",
    "for c in candidates:\n",
    "    if c in gdf.columns:\n",
    "        vals = gdf[c].unique()\n",
    "        found[c] = vals[:10] if len(vals)>10 else vals\n",
    "\n",
    "print(\"\\nDetected candidate name columns and sample values:\")\n",
    "for k,v in found.items():\n",
    "    print(k, \"->\", v)\n",
    "\n",
    "# Strategy to pick Gaza: try NAME_1 or similar containing 'Gaza' (case-insensitive),\n",
    "# otherwise pick polygon(s) whose centroid latitude < 31.7 (southern strip).\n",
    "gaza_gdf = None\n",
    "\n",
    "# 1) look for textual match in candidate columns\n",
    "for col in [\"NAME_1\",\"NAME\",\"VARNAME_1\",\"NAME_0\",\"ENGTYPE_1\"]:\n",
    "    if col in gdf.columns:\n",
    "        mask = gdf[col].astype(str).str.contains(\"gaza\", case=False, na=False)\n",
    "        if mask.any():\n",
    "            gaza_gdf = gdf[mask].copy()\n",
    "            print(f\"Selected Gaza from column '{col}' (text match).\")\n",
    "            break\n",
    "\n",
    "# 2) if not found, try numeric admin code if available (common GADM codes)\n",
    "if gaza_gdf is None:\n",
    "    for col in [\"GID_1\",\"GID_0\"]:\n",
    "        if col in gdf.columns:\n",
    "            # print a sample to help you manually choose\n",
    "            print(f\"Column {col} exists. Sample values: {gdf[col].unique()[:20]}\")\n",
    "            # don't auto-pick by code, leave for manual if needed\n",
    "\n",
    "# 3) fallback: geometry centroid latitude filter (safe for Gaza)\n",
    "if gaza_gdf is None:\n",
    "    # compute centroids (ensure geometry valid)\n",
    "    gdf = gdf[~gdf.geometry.is_empty].copy()\n",
    "    centroids = gdf.geometry.centroid\n",
    "    lat_vals = centroids.y\n",
    "    # Gaza is southern and coastal; centroid latitude < 31.7 tends to select Gaza features\n",
    "    mask = lat_vals < 31.7\n",
    "    if mask.any():\n",
    "        gaza_gdf = gdf[mask].copy()\n",
    "        print(\"Selected Gaza by centroid latitude < 31.7 (fallback).\")\n",
    "    else:\n",
    "        print(\"No features matched centroid latitude < 31.7; trying latitude < 31.9 ...\")\n",
    "        mask = lat_vals < 31.9\n",
    "        if mask.any():\n",
    "            gaza_gdf = gdf[mask].copy()\n",
    "            print(\"Selected Gaza by centroid latitude < 31.9 (fallback).\")\n",
    "\n",
    "# If still None, show hint and exit\n",
    "if gaza_gdf is None or gaza_gdf.empty:\n",
    "    raise RuntimeError(\"Could not automatically identify Gaza polygon. Inspect gdf.columns and gdf.head() for clues.\")\n",
    "\n",
    "# Dissolve into a single polygon (in case Gaza is multiple features)\n",
    "gaza_union = gaza_gdf.dissolve(by=None).reset_index(drop=True)\n",
    "print(\"Resulting Gaza features:\", len(gaza_union))\n",
    "# Optional: quick plot to verify\n",
    "ax = gaza_union.plot(figsize=(6,6))\n",
    "ax.set_title(\"Extracted Gaza polygon (verify visually)\")\n",
    "plt.show()\n",
    "\n",
    "# Save to GeoJSON\n",
    "out_path = r\"C:\\Users\\ctr22\\Downloads\\gaza_boundary.geojson\"\n",
    "gaza_union.to_file(out_path, driver=\"GeoJSON\")\n",
    "print(\"Saved Gaza boundary to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3b416e",
   "metadata": {},
   "source": [
    "Generates maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d9a3d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CODE EXECUTION STARTED\n",
      "Date and Time: 02/02/2026 14:13:06\n",
      "Run Tag: 20260202_141306\n",
      "================================================================================\n",
      "Reading hospitals...\n",
      "Loaded 5 hospitals; schedule events detected: 5\n",
      "Unique change dates across hospitals: 5\n",
      "Reading ACLED file...\n",
      "Hospitals with valid coords: 5\n",
      "Calculating closest hospitals for each attack...\n",
      "Total attacks: 28080, Attacks within 5km: 12943\n",
      "Saved modified ACLED file (only attacks within 5km) with hospital proximity columns to: ./v2_ACLED_within_5km_20260202_141306.xlsx\n",
      "Using Gaza polygon: gaza_boundary.geojson\n",
      "[interval 2023-12-01->2024-03-18] Attacks within 5km: 3098\n",
      "[voronoi] shapely.voronoi_diagram used; time=13.46s, points=5\n",
      "[interval 2023-12-01->2024-03-18] Voronoi build time: 13.46s\n",
      "Saved map: ./v2_gaza_catchment_20231201_to_20240318_20260202_141306.html\n",
      "[interval 2024-03-18->2024-04-01] Attacks within 5km: 337\n",
      "[voronoi] shapely.voronoi_diagram used; time=0.56s, points=4\n",
      "[interval 2024-03-18->2024-04-01] Voronoi build time: 0.56s\n",
      "Saved map: ./v2_gaza_catchment_20240318_to_20240401_20260202_141306.html\n",
      "[interval 2024-04-01->2024-04-30] Attacks within 5km: 564\n",
      "[voronoi] shapely.voronoi_diagram used; time=0.73s, points=5\n",
      "[interval 2024-04-01->2024-04-30] Voronoi build time: 0.73s\n",
      "Saved map: ./v2_gaza_catchment_20240401_to_20240430_20260202_141306.html\n",
      "[interval 2024-11-01->2025-01-30] Attacks within 5km: 1630\n",
      "[voronoi] shapely.voronoi_diagram used; time=1.11s, points=5\n",
      "[interval 2024-11-01->2025-01-30] Voronoi build time: 1.11s\n",
      "Saved map: ./v2_gaza_catchment_20241101_to_20250130_20260202_141306.html\n",
      "================================================================================\n",
      "CODE EXECUTION COMPLETED\n",
      "Completion Date and Time: 02/02/2026 14:13:53\n",
      "Total execution time: 47.16 seconds (0.79 minutes)\n",
      "Maps created: 4\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "gaza_catchment_safe.py\n",
    "\n",
    "Safer, robust end-to-end pipeline to build Gaza-clipped hospital catchment (Voronoi) maps\n",
    "and overlay ACLED attack heatmaps for specified date windows.\n",
    "\n",
    "Key improvements vs earlier script:\n",
    " - Uses shapely.ops.voronoi_diagram when available (fast, bounded via envelope)\n",
    " - SciPy fallback builds Voronoi inside a bounded bbox (no giant buffers)\n",
    " - NumPy 2.0 compatible (uses np.ptp)\n",
    " - Safety caps and timing prints to avoid infinite/very long runs\n",
    " - Robust normalization of Gaza boundary inputs\n",
    " - Assigns leftover slivers inside Gaza to nearest hospital to ensure full partitioning\n",
    "\n",
    "Edit the HOSP_PATH, ACLED_PATH, and GAZA_SHAPEFILE variables at the top before running.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon, MultiPolygon, box, shape\n",
    "from shapely.ops import unary_union\n",
    "from scipy.spatial import Voronoi\n",
    "import folium\n",
    "from folium.plugins import HeatMap\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# ---------------- USER CONFIG ----------------\n",
    "HOSP_PATH = \"Hospitals_OpenCloseoverTime.xlsx\"\n",
    "ACLED_PATH = \"ACLED_May_09_25_Gaza.xlsx\"\n",
    "GAZA_SHAPEFILE = \"gaza_boundary.geojson\"  # set to None to use bbox fallback\n",
    "\n",
    "OUT_DIR = \".\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Date windows requested\n",
    "WINDOWS = [\n",
    "    (datetime(2023, 12, 1), datetime(2024, 4, 30)),\n",
    "    (datetime(2024, 11, 1), datetime(2025, 1, 30)),\n",
    "]\n",
    "\n",
    "CRS_WGS84 = \"EPSG:4326\"\n",
    "CRS_WEBMERC = \"EPSG:3857\"\n",
    "\n",
    "# Safety / performance tuning\n",
    "VORONOI_POINT_CAP = 400          # abort if more hospitals than this\n",
    "VORONOI_BUFFER_METERS = 15000    # buffer for bounding box in projected coords (meters)\n",
    "BUFFER_DEG = 0.05\n",
    "\n",
    "# ---------------- Helpers: I/O & schedule parsing ----------------\n",
    "\n",
    "def read_hospitals_table(path):\n",
    "    \"\"\"\n",
    "    Parse the Hospitals_OpenCloseoverTime.xlsx file into:\n",
    "      - hospitals_df: columns ['Hospital','lon','lat', plus raw schedule marker columns]\n",
    "      - schedule_meta: list of (col_name, 'Open'/'Closed', datetime) for columns that carry dates\n",
    "    This function is robust to the header+date-in-row layout described earlier.\n",
    "    \"\"\"\n",
    "    raw_head = pd.read_excel(path, header=None, nrows=2)\n",
    "    full = pd.read_excel(path, header=0)\n",
    "    cols = list(full.columns)\n",
    "\n",
    "    def find_col(opts):\n",
    "        for o in opts:\n",
    "            for c in cols:\n",
    "                if isinstance(c, str) and c.strip().lower().startswith(o.lower()):\n",
    "                    return c\n",
    "        return None\n",
    "\n",
    "    hosp_col = find_col([\"hospital\", \"name\"])\n",
    "    lon_col = find_col([\"longitude (x)\", \"longitude\", \"lon\", \"x\"])\n",
    "    lat_col = find_col([\"latitude (y)\", \"latitude\", \"lat\", \"y\"])\n",
    "    if hosp_col is None or lon_col is None or lat_col is None:\n",
    "        raise ValueError(f\"Couldn't detect Hospital/lon/lat columns. Found: {cols}\")\n",
    "\n",
    "    # detect Open/Closed header columns and try to read date from second row\n",
    "    schedule_meta = []\n",
    "    for c in cols:\n",
    "        if isinstance(c, str):\n",
    "            lc = c.strip().lower()\n",
    "            if lc.startswith(\"open\") or lc.startswith(\"closed\"):\n",
    "                typ = \"Open\" if lc.startswith(\"open\") else \"Closed\"\n",
    "                dt = None\n",
    "                try:\n",
    "                    idx = cols.index(c)\n",
    "                    raw = raw_head.iat[1, idx]\n",
    "                    if pd.notnull(raw):\n",
    "                        dt = pd.to_datetime(raw)\n",
    "                except Exception:\n",
    "                    dt = None\n",
    "                schedule_meta.append((c, typ, dt))\n",
    "\n",
    "    # keep only entries which have a date (we need timestamps)\n",
    "    schedule_meta = [(c,t,d) for (c,t,d) in schedule_meta if d is not None]\n",
    "\n",
    "    # fallback: detect date-like column headers (rare case)\n",
    "    if not schedule_meta:\n",
    "        for c in cols:\n",
    "            try:\n",
    "                d = pd.to_datetime(c)\n",
    "                # try to infer whether this header corresponds to Open/Closed by reading raw_head[0, idx]\n",
    "                typ = None\n",
    "                try:\n",
    "                    idx = cols.index(c)\n",
    "                    hdr0 = raw_head.iat[0, idx]\n",
    "                    if isinstance(hdr0, str) and \"open\" in hdr0.lower():\n",
    "                        typ = \"Open\"\n",
    "                    elif isinstance(hdr0, str) and \"closed\" in hdr0.lower():\n",
    "                        typ = \"Closed\"\n",
    "                except Exception:\n",
    "                    typ = \"Open\"\n",
    "                schedule_meta.append((c, typ, d))\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    hospitals_df = full[[hosp_col, lon_col, lat_col]].rename(columns={hosp_col: \"Hospital\", lon_col: \"lon\", lat_col: \"lat\"})\n",
    "    hospitals_df[\"lon\"] = pd.to_numeric(hospitals_df[\"lon\"], errors=\"coerce\")\n",
    "    hospitals_df[\"lat\"] = pd.to_numeric(hospitals_df[\"lat\"], errors=\"coerce\")\n",
    "    # copy any schedule marker columns we detected\n",
    "    for c,_,_ in schedule_meta:\n",
    "        if c in full.columns:\n",
    "            hospitals_df[c] = full[c]\n",
    "\n",
    "    return hospitals_df, schedule_meta\n",
    "\n",
    "def build_hospital_open_intervals(hospitals_df, schedule_meta):\n",
    "    \"\"\"\n",
    "    From schedule_meta (col, typ, date), produce per-hospital ordered list of (date, status).\n",
    "    If per-row cells contain markers under schedule columns we respect them; otherwise use global schedule.\n",
    "    \"\"\"\n",
    "    # prepare events sorted by date\n",
    "    events = sorted([(pd.to_datetime(d).to_pydatetime(), col, typ) for (col, typ, d) in schedule_meta], key=lambda x: x[0])\n",
    "    hospital_intervals = {}\n",
    "    for _, row in hospitals_df.iterrows():\n",
    "        name = row[\"Hospital\"]\n",
    "        changes = []\n",
    "        # If per-row markers exist, use them\n",
    "        for dt, col, typ in events:\n",
    "            col_name = col\n",
    "            val = row.get(col_name, None) if col_name in row.index else None\n",
    "            if pd.notnull(val) and str(val).strip() != \"\":\n",
    "                changes.append((dt, typ))\n",
    "        # If none, fall back to global events\n",
    "        if not changes:\n",
    "            for dt, col, typ in events:\n",
    "                changes.append((dt, typ))\n",
    "        # compress consecutive duplicates\n",
    "        changes_sorted = sorted(changes, key=lambda x: x[0])\n",
    "        compressed = []\n",
    "        for dt, typ in changes_sorted:\n",
    "            if not compressed or compressed[-1][1] != typ:\n",
    "                compressed.append((dt, typ))\n",
    "        hospital_intervals[name] = compressed\n",
    "    return hospital_intervals\n",
    "\n",
    "def get_all_change_dates(hospital_intervals):\n",
    "    s = set()\n",
    "    for changes in hospital_intervals.values():\n",
    "        for dt, typ in changes:\n",
    "            s.add(pd.to_datetime(dt).to_pydatetime())\n",
    "    return sorted(list(s))\n",
    "\n",
    "# ---------------- Helpers: Gaza polygon normalization ----------------\n",
    "\n",
    "def normalize_clip_shape(clip_input, hospitals_gdf=None, acled_gdf=None):\n",
    "    \"\"\"\n",
    "    Accepts:\n",
    "      - path to geojson/shapefile (string)\n",
    "      - GeoDataFrame / GeoSeries\n",
    "      - shapely geometry or GeoJSON dict\n",
    "      - None (then use bbox around hospitals+attacks)\n",
    "    Returns:\n",
    "      GeoDataFrame (single row) in CRS_WGS84\n",
    "    \"\"\"\n",
    "    if clip_input is None:\n",
    "        # fallback to bbox around points\n",
    "        if hospitals_gdf is None or acled_gdf is None:\n",
    "            raise ValueError(\"clip_input is None and hospitals/acled not provided for bbox fallback.\")\n",
    "        combined = pd.concat([hospitals_gdf.dropna(subset=[\"geometry\"]), acled_gdf.dropna(subset=[\"geometry\"])], sort=False)\n",
    "        if combined.empty:\n",
    "            return gpd.GeoDataFrame(geometry=[box(34.2, 31.05, 35.6, 31.7)], crs=CRS_WGS84)\n",
    "        minx, miny, maxx, maxy = combined.total_bounds\n",
    "        bufx = (maxx - minx) * 0.1 + BUFFER_DEG\n",
    "        bufy = (maxy - miny) * 0.1 + BUFFER_DEG\n",
    "        return gpd.GeoDataFrame(geometry=[box(minx - bufx, miny - bufy, maxx + bufx, maxy + bufy)], crs=CRS_WGS84)\n",
    "\n",
    "    # If string path\n",
    "    if isinstance(clip_input, str):\n",
    "        if not os.path.exists(clip_input):\n",
    "            raise FileNotFoundError(f\"GAZA_SHAPEFILE path not found: {clip_input}\")\n",
    "        g = gpd.read_file(clip_input)\n",
    "        if g.crs is None:\n",
    "            g = g.set_crs(CRS_WGS84)\n",
    "        g = g.to_crs(CRS_WGS84)\n",
    "        unified = g.dissolve(by=None).reset_index(drop=True)\n",
    "        return unified\n",
    "\n",
    "    if isinstance(clip_input, gpd.GeoDataFrame):\n",
    "        g = clip_input.copy()\n",
    "        if g.crs is None:\n",
    "            g = g.set_crs(CRS_WGS84)\n",
    "        g = g.to_crs(CRS_WGS84)\n",
    "        return g.dissolve(by=None).reset_index(drop=True)\n",
    "\n",
    "    if isinstance(clip_input, gpd.GeoSeries):\n",
    "        return gpd.GeoDataFrame(geometry=[unary_union(clip_input.values)], crs=CRS_WGS84)\n",
    "\n",
    "    if hasattr(clip_input, \"geom_type\"):\n",
    "        return gpd.GeoDataFrame(geometry=[clip_input], crs=CRS_WGS84)\n",
    "\n",
    "    if isinstance(clip_input, dict):\n",
    "        t = clip_input.get(\"type\", \"\").lower()\n",
    "        geom = None\n",
    "        if t == \"featurecollection\":\n",
    "            geoms = []\n",
    "            for f in clip_input.get(\"features\", []):\n",
    "                g = f.get(\"geometry\", None)\n",
    "                if g:\n",
    "                    geoms.append(shape(g))\n",
    "            if not geoms:\n",
    "                raise ValueError(\"FeatureCollection contained no valid geometries.\")\n",
    "            geom = unary_union(geoms)\n",
    "        elif t == \"feature\":\n",
    "            geom = shape(clip_input.get(\"geometry\"))\n",
    "        else:\n",
    "            features = clip_input.get(\"features\", None)\n",
    "            if features:\n",
    "                geoms = [shape(f[\"geometry\"]) for f in features if \"geometry\" in f]\n",
    "                geom = unary_union(geoms)\n",
    "        if geom is None:\n",
    "            raise ValueError(\"Unsupported GeoJSON dict for clip_input.\")\n",
    "        return gpd.GeoDataFrame(geometry=[geom], crs=CRS_WGS84)\n",
    "\n",
    "    raise TypeError(\"Unsupported clip_input type for normalize_clip_shape\")\n",
    "\n",
    "# ---------------- Safer Voronoi builder (preferred shapely, bounded SciPy fallback) ----------------\n",
    "\n",
    "from shapely import geometry as shapely_geom\n",
    "try:\n",
    "    # shapely.ops.voronoi_diagram exists in Shapely >=2.0\n",
    "    from shapely.ops import voronoi_diagram\n",
    "    _HAS_SHAPELY_VORONOI = True\n",
    "except Exception:\n",
    "    voronoi_diagram = None\n",
    "    _HAS_SHAPELY_VORONOI = False\n",
    "\n",
    "def voronoi_polygons_clipped(points_gdf, clip_gdf):\n",
    "    \"\"\"\n",
    "    Build Voronoi regions for points_gdf and clip them to clip_gdf (WGS84).\n",
    "    Safer: prefers shapely.voronoi_diagram with a bounded envelope; falls back to SciPy Voronoi\n",
    "    with a bbox in projected CRS to avoid infinite/unbounded polygons.\n",
    "    Returns GeoDataFrame with ['geometry','Hospital'] in WGS84.\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    if points_gdf.empty:\n",
    "        return gpd.GeoDataFrame(columns=[\"geometry\", \"Hospital\"], crs=CRS_WGS84)\n",
    "\n",
    "    npts = len(points_gdf)\n",
    "    if npts > VORONOI_POINT_CAP:\n",
    "        raise RuntimeError(f\"Too many hospital points ({npts}) for Voronoi (cap={VORONOI_POINT_CAP}). Reduce points or increase cap.\")\n",
    "\n",
    "    # prepare projected and wgs geometries\n",
    "    pts_wgs = points_gdf.reset_index(drop=True).to_crs(CRS_WGS84)\n",
    "    pts_proj = points_gdf.reset_index(drop=True).to_crs(CRS_WEBMERC)\n",
    "\n",
    "    # union clip polygon\n",
    "    clip_union = clip_gdf.unary_union\n",
    "\n",
    "    # Build a modest bounding envelope in projected coordinates for safe clipping\n",
    "    clip_proj = gpd.GeoSeries([clip_union], crs=CRS_WGS84).to_crs(CRS_WEBMERC)\n",
    "    minx, miny, maxx, maxy = clip_proj.total_bounds\n",
    "    buf = VORONOI_BUFFER_METERS\n",
    "    bbox_proj = shapely_geom.box(minx - buf, miny - buf, maxx + buf, maxy + buf)\n",
    "\n",
    "    # Try shapely.voronoi_diagram if available\n",
    "    if _HAS_SHAPELY_VORONOI:\n",
    "        try:\n",
    "            multip = shapely_geom.MultiPoint([(pt.x, pt.y) for pt in pts_proj.geometry])\n",
    "            vor = voronoi_diagram(multip, envelope=bbox_proj, tolerance=0.0)\n",
    "            # extract polygons from vor (which may be GeometryCollection)\n",
    "            poly_list = []\n",
    "            if vor.is_empty:\n",
    "                poly_list = []\n",
    "            else:\n",
    "                # keep only polygonal pieces\n",
    "                try:\n",
    "                    for g in vor.geoms:\n",
    "                        if isinstance(g, (Polygon, MultiPolygon)):\n",
    "                            poly_list.append(g)\n",
    "                except Exception:\n",
    "                    # vor may be a Polygon directly\n",
    "                    if isinstance(vor, (Polygon, MultiPolygon)):\n",
    "                        poly_list = [vor]\n",
    "            # assign polygons to nearest hospital by centroid\n",
    "            polys_proj_gdf = gpd.GeoDataFrame(geometry=poly_list, crs=CRS_WEBMERC)\n",
    "            polys_wgs = polys_proj_gdf.to_crs(CRS_WGS84).reset_index(drop=True)\n",
    "\n",
    "            hosp_points_wgs = pts_wgs.set_geometry(pts_wgs.geometry).copy()\n",
    "            assigned = []\n",
    "            for poly in polys_wgs.geometry:\n",
    "                if poly is None or poly.is_empty:\n",
    "                    continue\n",
    "                rep = poly.representative_point()\n",
    "                dists = hosp_points_wgs.geometry.distance(rep)\n",
    "                nearest_idx = int(dists.idxmin())\n",
    "                hosp_name = hosp_points_wgs.loc[nearest_idx, 'Hospital']\n",
    "                clipped_poly = poly.intersection(clip_union)\n",
    "                if clipped_poly is None or clipped_poly.is_empty:\n",
    "                    continue\n",
    "                assigned.append((hosp_name, clipped_poly))\n",
    "\n",
    "            # build result ensuring every hospital present\n",
    "            rows = []\n",
    "            for hosp in pts_wgs['Hospital'].values:\n",
    "                polys_for = [p for (h, p) in assigned if h == hosp]\n",
    "                geom_union = unary_union(polys_for) if polys_for else Polygon()\n",
    "                rows.append({'Hospital': hosp, 'geometry': geom_union})\n",
    "            result = gpd.GeoDataFrame(rows, crs=CRS_WGS84)\n",
    "            elapsed = time.time() - t0\n",
    "            print(f\"[voronoi] shapely.voronoi_diagram used; time={elapsed:.2f}s, points={npts}\")\n",
    "            return result[['geometry','Hospital']]\n",
    "        except Exception as e:\n",
    "            print(f\"[voronoi] shapely.voronoi_diagram failed: {e}. Falling back to SciPy bounded Voronoi.\")\n",
    "\n",
    "    # ---------- SciPy fallback (bounded by bbox_proj) ----------\n",
    "    coords = np.array([(pt.x, pt.y) for pt in pts_proj.geometry])\n",
    "    vor = Voronoi(coords)\n",
    "\n",
    "    proj_polys = []\n",
    "    for pt_idx, region_index in enumerate(vor.point_region):\n",
    "        region = vor.regions[region_index]\n",
    "        if not region or -1 in region:\n",
    "            # infinite region: build convex hull of site + bbox corners (bounded)\n",
    "            site = coords[pt_idx]\n",
    "            bbox_coords = np.array(bbox_proj.exterior.coords)\n",
    "            pts_for_hull = np.vstack([site, bbox_coords])\n",
    "            hull = shapely_geom.MultiPoint([tuple(p) for p in pts_for_hull]).convex_hull\n",
    "            poly = hull\n",
    "        else:\n",
    "            try:\n",
    "                verts = [vor.vertices[i] for i in region]\n",
    "                poly = Polygon(verts)\n",
    "            except Exception:\n",
    "                site = coords[pt_idx]\n",
    "                bbox_coords = np.array(bbox_proj.exterior.coords)\n",
    "                pts_for_hull = np.vstack([site, bbox_coords])\n",
    "                hull = shapely_geom.MultiPoint([tuple(p) for p in pts_for_hull]).convex_hull\n",
    "                poly = hull\n",
    "        # clip to bbox_proj to keep finite\n",
    "        poly_clipped = poly.intersection(bbox_proj)\n",
    "        proj_polys.append(poly_clipped)\n",
    "\n",
    "    polys_proj_gdf = gpd.GeoDataFrame(geometry=proj_polys, crs=CRS_WEBMERC)\n",
    "    polys_wgs = polys_proj_gdf.to_crs(CRS_WGS84).reset_index(drop=True)\n",
    "\n",
    "    # assign each polygon to the corresponding hospital (order preserved)\n",
    "    hosp_names = pts_wgs['Hospital'].values\n",
    "    rows = []\n",
    "    for i, poly in enumerate(polys_wgs.geometry):\n",
    "        try:\n",
    "            clipped = poly.intersection(clip_union)\n",
    "        except Exception:\n",
    "            clipped = Polygon()\n",
    "        rows.append({'Hospital': hosp_names[i], 'geometry': (clipped if clipped is not None else Polygon())})\n",
    "    result = gpd.GeoDataFrame(rows, crs=CRS_WGS84)\n",
    "\n",
    "    # If leftover area in clip_union remains, assign pieces to nearest hospital\n",
    "    covered = unary_union([g for g in result.geometry if g is not None and not g.is_empty])\n",
    "    leftover = clip_union.difference(covered) if covered is not None else clip_union\n",
    "    if leftover and not leftover.is_empty:\n",
    "        pieces = [leftover] if isinstance(leftover, Polygon) else list(leftover.geoms)\n",
    "        hosp_pts = pts_wgs.geometry\n",
    "        for piece in pieces:\n",
    "            rep = piece.representative_point()\n",
    "            dists = hosp_pts.distance(rep)\n",
    "            nearest_idx = int(dists.idxmin())\n",
    "            cur = result.loc[result['Hospital'] == hosp_names[nearest_idx], 'geometry'].values[0]\n",
    "            if cur is None or cur.is_empty:\n",
    "                result.loc[result['Hospital'] == hosp_names[nearest_idx], 'geometry'] = [piece]\n",
    "            else:\n",
    "                result.loc[result['Hospital'] == hosp_names[nearest_idx], 'geometry'] = [cur.union(piece)]\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    print(f\"[voronoi] SciPy fallback complete; time={elapsed:.2f}s, points={npts}\")\n",
    "    return result[['geometry','Hospital']]\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate haversine distance between points in kilometers.\n",
    "    All inputs are numpy arrays (can be 1D or 2D), function returns distances in km.\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    km = 6371.0 * c\n",
    "    return km\n",
    "\n",
    "def find_closest_hospital_for_attacks(acled_gdf, hosp_gdf, hospital_intervals, date_col):\n",
    "    \"\"\"\n",
    "    For each attack in acled_gdf, find the closest open hospital.\n",
    "    Returns a DataFrame with columns: 'Closest Hospital', 'Distance to Closest Hospital (km)', 'In Proximity?'\n",
    "    'Closest Hospital' is the closest hospital that was open at the time of the attack.\n",
    "    'In Proximity?' is 'Yes' if the closest open hospital is within 5 km, 'No' otherwise.\n",
    "    \"\"\"\n",
    "    result_data = []\n",
    "    \n",
    "    # Get hospital coordinates as arrays\n",
    "    hosp_names = hosp_gdf['Hospital'].values\n",
    "    hosp_lons = hosp_gdf.geometry.x.values\n",
    "    hosp_lats = hosp_gdf.geometry.y.values\n",
    "    \n",
    "    # Get attack coordinates\n",
    "    attack_lons = acled_gdf.geometry.x.values\n",
    "    attack_lats = acled_gdf.geometry.y.values\n",
    "    attack_dates = acled_gdf[date_col].values\n",
    "    \n",
    "    for i in range(len(acled_gdf)):\n",
    "        attack_date = pd.to_datetime(attack_dates[i]).to_pydatetime()\n",
    "        attack_lon = attack_lons[i]\n",
    "        attack_lat = attack_lats[i]\n",
    "        \n",
    "        # Find which hospitals were open at the time of this attack\n",
    "        open_hosp_indices = []\n",
    "        open_hosp_names_list = []\n",
    "        for j, hosp_name in enumerate(hosp_names):\n",
    "            # Check if hospital was open at attack date\n",
    "            if hosp_name in hospital_intervals:\n",
    "                evs = hospital_intervals[hosp_name]\n",
    "                last_status = None\n",
    "                for dt, typ in evs:\n",
    "                    if dt <= attack_date:\n",
    "                        last_status = typ\n",
    "                    else:\n",
    "                        break\n",
    "                if last_status == \"Open\":\n",
    "                    open_hosp_indices.append(j)\n",
    "                    open_hosp_names_list.append(hosp_name)\n",
    "        \n",
    "        if not open_hosp_indices:\n",
    "            # No open hospitals at this time\n",
    "            result_data.append({\n",
    "                'Closest Hospital': None,\n",
    "                'Distance to Closest Hospital (km)': np.nan,\n",
    "                'In Proximity?': 'No'\n",
    "            })\n",
    "        else:\n",
    "            # Calculate distances to all open hospitals\n",
    "            open_hosp_lons = hosp_lons[open_hosp_indices]\n",
    "            open_hosp_lats = hosp_lats[open_hosp_indices]\n",
    "            \n",
    "            # Calculate distances using haversine\n",
    "            # Broadcast single attack point to all open hospitals\n",
    "            distances = haversine_np(\n",
    "                np.full(len(open_hosp_lons), attack_lon),\n",
    "                np.full(len(open_hosp_lats), attack_lat),\n",
    "                open_hosp_lons,\n",
    "                open_hosp_lats\n",
    "            )\n",
    "            \n",
    "            # Find closest\n",
    "            closest_idx = np.argmin(distances)\n",
    "            closest_dist_km = distances[closest_idx]\n",
    "            closest_hosp_name = open_hosp_names_list[closest_idx]\n",
    "            \n",
    "            # Check if within 5 km\n",
    "            in_proximity = 'Yes' if closest_dist_km <= 5.0 else 'No'\n",
    "            \n",
    "            result_data.append({\n",
    "                'Closest Hospital': closest_hosp_name,\n",
    "                'Distance to Closest Hospital (km)': closest_dist_km,\n",
    "                'In Proximity?': in_proximity\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(result_data)\n",
    "\n",
    "def pts_to_heatlist(acled_gdf, round_decimals=5):\n",
    "    \"\"\"\n",
    "    Turn an ACLED GeoDataFrame into a HeatMap-style list [[lat, lon, weight], ...]\n",
    "    Aggregates by rounded coordinates so co-located events increase weight.\n",
    "    Returns (heat_list, max_weight) where max_weight is used as HeatMap max_val.\n",
    "    \"\"\"\n",
    "    if acled_gdf is None or acled_gdf.empty:\n",
    "        return [], 1\n",
    "\n",
    "    df = acled_gdf.copy()\n",
    "    # ensure geometry present\n",
    "    df = df[~df.geometry.is_empty & df.geometry.notna()].copy()\n",
    "    if df.empty:\n",
    "        return [], 1\n",
    "\n",
    "    df[\"lon\"] = df.geometry.x\n",
    "    df[\"lat\"] = df.geometry.y\n",
    "    # round to avoid tiny floating differences for truly colocated events\n",
    "    df[\"lon_r\"] = df[\"lon\"].round(round_decimals)\n",
    "    df[\"lat_r\"] = df[\"lat\"].round(round_decimals)\n",
    "\n",
    "    grouped = df.groupby([\"lat_r\", \"lon_r\"]).size().reset_index(name=\"count\")\n",
    "    # build heat list in the format expected by folium.plugins.HeatMap: [lat, lon, weight]\n",
    "    heat = grouped.apply(lambda r: [float(r[\"lat_r\"]), float(r[\"lon_r\"]), float(r[\"count\"])], axis=1).tolist()\n",
    "    max_weight = float(grouped[\"count\"].max()) if not grouped.empty else 1.0\n",
    "    return heat, max_weight\n",
    "\n",
    "\n",
    "# ---------------- Main pipeline ----------------\n",
    "def main():\n",
    "    start_run = time.time()\n",
    "    run_dt = datetime.now()\n",
    "    run_display = run_dt.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    run_tag = run_dt.strftime(\"%Y%m%d_%H%M%S\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"CODE EXECUTION STARTED\")\n",
    "    print(f\"Date and Time: {run_display}\")\n",
    "    print(f\"Run Tag: {run_tag}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    print(\"Reading hospitals...\")\n",
    "    hospitals_df, schedule_meta = read_hospitals_table(HOSP_PATH)\n",
    "    print(f\"Loaded {len(hospitals_df)} hospitals; schedule events detected: {len(schedule_meta)}\")\n",
    "\n",
    "    hospital_intervals = build_hospital_open_intervals(hospitals_df, schedule_meta)\n",
    "    all_change_dates = get_all_change_dates(hospital_intervals)\n",
    "    print(f\"Unique change dates across hospitals: {len(all_change_dates)}\")\n",
    "\n",
    "    print(\"Reading ACLED file...\")\n",
    "    acled = pd.read_excel(ACLED_PATH)\n",
    "    ac_cols = list(acled.columns)\n",
    "\n",
    "    # prefer explicit 'event_date' column if present\n",
    "    date_col = None\n",
    "    if any(str(c).strip().lower() == \"event_date\" for c in ac_cols):\n",
    "        # find the exact column name that matches event_date\n",
    "        date_col = next(c for c in ac_cols if str(c).strip().lower() == \"event_date\")\n",
    "    else:\n",
    "        # fallback detection\n",
    "        date_col = next((c for c in ac_cols if \"date\" in str(c).lower() or \"event_date\" in str(c).lower()), None)\n",
    "        if date_col is None:\n",
    "            for c in ac_cols:\n",
    "                try:\n",
    "                    pd.to_datetime(acled[c].dropna().iloc[0])\n",
    "                    date_col = c\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "    if date_col is None:\n",
    "        raise ValueError(\"Couldn't detect date column in ACLED file. Looked for 'event_date' and other date-like columns.\")\n",
    "\n",
    "    lon_col = next((c for c in ac_cols if \"lon\" in str(c).lower() or \"longitude\" in str(c).lower() or str(c).lower() == \"x\"), None)\n",
    "    lat_col = next((c for c in ac_cols if \"lat\" in str(c).lower() or \"latitude\" in str(c).lower() or str(c).lower() == \"y\"), None)\n",
    "    if lon_col is None or lat_col is None:\n",
    "        raise ValueError(f\"Couldn't detect lon/lat columns in ACLED file. Columns: {ac_cols}\")\n",
    "\n",
    "    # parse event_date explicitly and drop bad rows\n",
    "    acled[date_col] = pd.to_datetime(acled[date_col], errors=\"coerce\")\n",
    "    acled = acled.dropna(subset=[lon_col, lat_col, date_col]).copy()\n",
    "\n",
    "    # Create GeoDataFrame using the precise lat/lon columns detected\n",
    "    acled_gdf = gpd.GeoDataFrame(\n",
    "        acled,\n",
    "        geometry=gpd.points_from_xy(acled[lon_col].astype(float), acled[lat_col].astype(float)),\n",
    "        crs=CRS_WGS84\n",
    "    )\n",
    "\n",
    "    # hospitals geo\n",
    "    hosp_gdf = gpd.GeoDataFrame(\n",
    "        hospitals_df.dropna(subset=[\"lon\", \"lat\"]),\n",
    "        geometry=gpd.points_from_xy(hospitals_df[\"lon\"].astype(float), hospitals_df[\"lat\"].astype(float)),\n",
    "        crs=CRS_WGS84\n",
    "    )\n",
    "    print(f\"Hospitals with valid coords: {len(hosp_gdf)}\")\n",
    "\n",
    "    # Calculate closest hospital for each attack and add columns\n",
    "    print(\"Calculating closest hospitals for each attack...\")\n",
    "    closest_hosp_df = find_closest_hospital_for_attacks(acled_gdf, hosp_gdf, hospital_intervals, date_col)\n",
    "    \n",
    "    # Add the new columns to acled (convert back to DataFrame first, then add columns)\n",
    "    acled_with_cols = acled_gdf.copy()\n",
    "    acled_with_cols['Closest Hospital'] = closest_hosp_df['Closest Hospital'].values\n",
    "    acled_with_cols['Distance to Closest Hospital (km)'] = closest_hosp_df['Distance to Closest Hospital (km)'].values\n",
    "    acled_with_cols['In Proximity?'] = closest_hosp_df['In Proximity?'].values\n",
    "    \n",
    "    # Filter to only include attacks within 5km of closest hospital\n",
    "    acled_within_5km = acled_with_cols[acled_with_cols['In Proximity?'] == 'Yes'].copy()\n",
    "    print(f\"Total attacks: {len(acled_with_cols)}, Attacks within 5km: {len(acled_within_5km)}\")\n",
    "    \n",
    "    # Save the modified ACLED file - only attacks within 5km (avoid overwriting prior outputs)\n",
    "    output_acled_path = os.path.join(OUT_DIR, f\"v2_ACLED_within_5km_{run_tag}.xlsx\")\n",
    "    # Convert GeoDataFrame back to DataFrame for Excel export (drop geometry column)\n",
    "    acled_output = acled_within_5km.drop(columns=['geometry']).copy()\n",
    "    acled_output.to_excel(output_acled_path, index=False)\n",
    "    print(f\"Saved modified ACLED file (only attacks within 5km) with hospital proximity columns to: {output_acled_path}\")\n",
    "    \n",
    "    # normalize clip (Gaza)\n",
    "    clip_input = GAZA_SHAPEFILE if (GAZA_SHAPEFILE and os.path.exists(GAZA_SHAPEFILE)) else None\n",
    "    if clip_input:\n",
    "        print(\"Using Gaza polygon:\", clip_input)\n",
    "    else:\n",
    "        print(\"No valid Gaza polygon provided; will fallback to bbox around data.\")\n",
    "\n",
    "    try:\n",
    "        clip_gdf = normalize_clip_shape(clip_input, hospitals_gdf=hosp_gdf, acled_gdf=acled_gdf)\n",
    "    except Exception as e:\n",
    "        print(\"normalize_clip_shape failed:\", e)\n",
    "        # fallback bbox\n",
    "        combined = pd.concat([hosp_gdf.geometry, acled_gdf.geometry])\n",
    "        minx, miny, maxx, maxy = combined.total_bounds\n",
    "        clip_gdf = gpd.GeoDataFrame(geometry=[box(minx - 0.05, miny - 0.05, maxx + 0.05, maxy + 0.05)], crs=CRS_WGS84)\n",
    "        print(\"Using fallback bbox:\", clip_gdf.total_bounds)\n",
    "\n",
    "    # For each window, build intervals and maps\n",
    "    maps_created = 0\n",
    "\n",
    "    # helper: precise aggregation for heatmap (uses event_date filtering already done below)\n",
    "    def pts_to_heatlist_precise(acled_subset_gdf, round_decimals=6):\n",
    "        \"\"\"\n",
    "        Aggregate attack points by rounded lat/lon to produce weighted heatmap points.\n",
    "        Uses a relatively high precision (default 6 decimals) to remain specific.\n",
    "        Returns (heat_list, max_weight).\n",
    "        \"\"\"\n",
    "        if acled_subset_gdf is None or acled_subset_gdf.empty:\n",
    "            return [], 1.0\n",
    "\n",
    "        df = acled_subset_gdf.copy()\n",
    "        # remove empties\n",
    "        df = df[~df.geometry.is_empty & df.geometry.notna()].copy()\n",
    "        if df.empty:\n",
    "            return [], 1.0\n",
    "\n",
    "        # extract precise coords from geometry (use geometry.x / geometry.y directly)\n",
    "        df[\"lon\"] = df.geometry.x.astype(float)\n",
    "        df[\"lat\"] = df.geometry.y.astype(float)\n",
    "\n",
    "        # round coordinates to given decimals to aggregate near-identical points while preserving precision\n",
    "        df[\"lon_r\"] = df[\"lon\"].round(round_decimals)\n",
    "        df[\"lat_r\"] = df[\"lat\"].round(round_decimals)\n",
    "\n",
    "        # group by rounded coordinates to count number of attack records at each precise location\n",
    "        grouped = df.groupby([\"lat_r\", \"lon_r\"]).size().reset_index(name=\"count\")\n",
    "\n",
    "        # convert to HeatMap format: [lat, lon, weight]\n",
    "        heat = grouped.apply(lambda r: [float(r[\"lat_r\"]), float(r[\"lon_r\"]), float(r[\"count\"])], axis=1).tolist()\n",
    "        max_weight = float(grouped[\"count\"].max()) if not grouped.empty else 1.0\n",
    "        return heat, max_weight\n",
    "\n",
    "    for window_start, window_end in WINDOWS:\n",
    "        dates_in_window = [d for d in all_change_dates if (d >= window_start and d <= window_end)]\n",
    "        combined_dates = sorted(list(set(dates_in_window + [window_start, window_end])))\n",
    "        for a, b in zip(combined_dates[:-1], combined_dates[1:]):\n",
    "            # We will count attacks whose event_date is in [a, b)\n",
    "            interval_mid = a + (b - a) / 2\n",
    "\n",
    "            # find open hospitals at mid\n",
    "            open_hosp_names = []\n",
    "            for hosp, evs in hospital_intervals.items():\n",
    "                last_status = None\n",
    "                for dt, typ in evs:\n",
    "                    if dt <= interval_mid:\n",
    "                        last_status = typ\n",
    "                    else:\n",
    "                        break\n",
    "                if last_status == \"Open\":\n",
    "                    open_hosp_names.append(hosp)\n",
    "            if not open_hosp_names:\n",
    "                print(f\"[{a.date()} to {b.date()}] No open hospitals -> skipping.\")\n",
    "                continue\n",
    "\n",
    "            open_pts = hosp_gdf[hosp_gdf[\"Hospital\"].isin(open_hosp_names)].copy()\n",
    "            if open_pts.empty:\n",
    "                print(f\"[{a.date()} to {b.date()}] Open hospital names found but no coordinates -> skipping.\")\n",
    "                continue\n",
    "\n",
    "            # filter ACLED by event_date explicitly - only use attacks within 5km (already filtered)\n",
    "            attacks_interval_filtered = acled_within_5km[(acled_within_5km[date_col] >= a) & (acled_within_5km[date_col] < b)].copy()\n",
    "            print(f\"[interval {a.date()}->{b.date()}] Attacks within 5km: {len(attacks_interval_filtered)}\")\n",
    "\n",
    "            # Build voronoi polygons clipped to Gaza\n",
    "            t_v0 = time.time()\n",
    "            vor_polys = voronoi_polygons_clipped(open_pts, clip_gdf)\n",
    "            t_v1 = time.time()\n",
    "            print(f\"[interval {a.date()}->{b.date()}] Voronoi build time: {t_v1 - t_v0:.2f}s\")\n",
    "\n",
    "            # Build folium map\n",
    "            minx, miny, maxx, maxy = clip_gdf.total_bounds\n",
    "            center = [(miny + maxy) / 2, (minx + maxx) / 2]\n",
    "            m = folium.Map(location=center, zoom_start=11)\n",
    "\n",
    "            # color palette (used for outline strokes)\n",
    "            palette = [\"#e41a1c\", \"#377eb8\", \"#4daf4a\", \"#984ea3\", \"#ff7f00\", \"#ffff33\", \"#a65628\", \"#f781bf\", \"#999999\"]\n",
    "            random.shuffle(palette)\n",
    "\n",
    "            # add polygons as outlines only (no fill)\n",
    "            for i, row in vor_polys.reset_index(drop=True).iterrows():\n",
    "                hosp_name = row['Hospital']\n",
    "                geom = row['geometry']\n",
    "                if geom is None or geom.is_empty:\n",
    "                    continue\n",
    "                style = {\n",
    "                    \"fillOpacity\": 0.0,     # no fill\n",
    "                    \"fill\": False,\n",
    "                    \"color\": palette[i % len(palette)],   # stroke color\n",
    "                    \"weight\": 2,            # stroke width\n",
    "                    \"opacity\": 0.9\n",
    "                }\n",
    "                folium.GeoJson(\n",
    "                    data=gpd.GeoSeries([geom]).__geo_interface__,\n",
    "                    name=hosp_name,\n",
    "                    tooltip=str(hosp_name),\n",
    "                    style_function=lambda feature, style=style: style\n",
    "                ).add_to(m)\n",
    "\n",
    "            # add hospital markers (outline-only small circle)\n",
    "            for _, hr in open_pts.iterrows():\n",
    "                folium.CircleMarker(\n",
    "                    location=(hr.geometry.y, hr.geometry.x),\n",
    "                    radius=4,\n",
    "                    popup=str(hr.Hospital),\n",
    "                    fill=True,\n",
    "                    fillOpacity=0.9,\n",
    "                    weight=1\n",
    "                ).add_to(m)\n",
    "\n",
    "            # add weighted heatmap of attacks in interval (if any). Use high precision rounding for lat/lon.\n",
    "            # Only show attacks within 5 km of closest hospital\n",
    "            if not attacks_interval_filtered.empty:\n",
    "                heat, max_weight = pts_to_heatlist_precise(attacks_interval_filtered, round_decimals=6)\n",
    "\n",
    "                # gradient mapping (0..1)\n",
    "                gradient = {\n",
    "                    0.0: 'blue',\n",
    "                    0.2: 'lime',\n",
    "                    0.4: 'yellow',\n",
    "                    0.6: 'orange',\n",
    "                    0.8: 'red',\n",
    "                    1.0: 'darkred'\n",
    "                }\n",
    "\n",
    "                HeatMap(\n",
    "                    heat,\n",
    "                    radius=12,\n",
    "                    blur=18,\n",
    "                    max_zoom=13,\n",
    "                    gradient=gradient,\n",
    "                    max_val=max_weight\n",
    "                ).add_to(m)\n",
    "\n",
    "                # Add legend/colorbar matching gradient & show counts based on event_date aggregation\n",
    "                legend_html = f\"\"\"\n",
    "                <div style=\"\n",
    "                    position: fixed;\n",
    "                    bottom: 30px;\n",
    "                    left: 10px;\n",
    "                    z-index:9999;\n",
    "                    background:white;\n",
    "                    padding:8px;\n",
    "                    border:1px solid grey;\n",
    "                    font-size:12px;\n",
    "                    \">\n",
    "                  <b>Attack density (per interval)</b><br/>\n",
    "                  <div style=\"width:200px; height:12px; background:linear-gradient(to right,\n",
    "                        {gradient[0.0]}, {gradient[0.2]}, {gradient[0.4]}, {gradient[0.6]}, {gradient[0.8]}, {gradient[1.0]});\n",
    "                        margin-top:6px; border:1px solid #ccc;\"></div>\n",
    "                  <div style=\"display:flex; justify-content:space-between; margin-top:4px;\">\n",
    "                    <span>0</span><span>{int(max_weight//2)}</span><span>{int(max_weight)}</span>\n",
    "                  </div>\n",
    "                  <div style=\"margin-top:6px;\">\n",
    "                    <small>Counts reflect number of ACLED records (by <b>event_date</b>) aggregated at precise coordinates (rounded to 6 decimals).</small>\n",
    "                  </div>\n",
    "                </div>\n",
    "                \"\"\"\n",
    "                m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "            # add title box\n",
    "            title_html = f\"\"\"\n",
    "            <div style=\"position: fixed; top: 10px; left: 10px; z-index: 9999; background: white;\n",
    "                         padding: 8px; border: 1px solid grey; font-size:12px;\">\n",
    "                <b>Run:</b> {run_display}<br/>\n",
    "                <b>Interval:</b> {a.strftime('%Y-%m-%d')} â†’ {b.strftime('%Y-%m-%d')}<br/>\n",
    "                <b>Open hospitals:</b> {', '.join(open_hosp_names)}\n",
    "            </div>\n",
    "            \"\"\"\n",
    "            m.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "            fname = os.path.join(OUT_DIR, f\"v2_gaza_catchment_{a.strftime('%Y%m%d')}_to_{b.strftime('%Y%m%d')}_{run_tag}.html\")\n",
    "            m.save(fname)\n",
    "            maps_created += 1\n",
    "            print(f\"Saved map: {fname}\")\n",
    "\n",
    "    total_elapsed = time.time() - start_run\n",
    "    end_dt = datetime.now()\n",
    "    end_display = end_dt.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"CODE EXECUTION COMPLETED\")\n",
    "    print(f\"Completion Date and Time: {end_display}\")\n",
    "    print(f\"Total execution time: {total_elapsed:.2f} seconds ({total_elapsed/60:.2f} minutes)\")\n",
    "    print(f\"Maps created: {maps_created}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
