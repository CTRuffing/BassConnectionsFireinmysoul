{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c315ac09",
   "metadata": {},
   "source": [
    "OT Summary (Nasser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0920b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"Update2_Injury_Categorization_OT.summary.20-Apr-2025 2.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# keep your original cleaning\n",
    "df['Date of Surgical Encounter'] = pd.to_datetime(df['Date of Surgical Encounter'], errors='coerce')\n",
    "df = df.dropna(subset=['Date of Surgical Encounter']).copy()\n",
    "\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# ---------------- Biweekly bucketing anchored to first date ----------------\n",
    "# Anchor start to the earliest date (normalized to midnight)\n",
    "start_date = df['Date of Surgical Encounter'].min().normalize()\n",
    "\n",
    "# compute integer biweek index (0 = first 14-day period starting at start_date)\n",
    "df['biweek_idx'] = ((df['Date of Surgical Encounter'] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# aggregate by biweek index\n",
    "biweekly = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# create readable start/end labels for each biweek\n",
    "biweekly['period_start'] = start_date + pd.to_timedelta(biweekly['biweek_idx'] * 14, unit='D')\n",
    "biweekly['period_end'] = biweekly['period_start'] + pd.to_timedelta(13, unit='D')\n",
    "\n",
    "# human-friendly label (change format if you prefer)\n",
    "biweekly['period'] = (\n",
    "    biweekly['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "# final dataframe with period first, then injury columns\n",
    "final_df_OT_summary = biweekly[['period'] + injury_columns].copy()\n",
    "\n",
    "# optional: sort by period (already in order because biweek_idx increases)\n",
    "final_df_OT_summary = final_df_OT_summary.sort_values('period').reset_index(drop=True)\n",
    "\n",
    "print(final_df_OT_summary)\n",
    "\n",
    "out_path = \"biweekly_injury_aggregates_OT.xlsx\"\n",
    "final_df_OT_summary.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"Saved aggregated file to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82542bb6",
   "metadata": {},
   "source": [
    "EGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e5df96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1) Load file ---------------------------------------------------------\n",
    "file_path = \"InjuryCategorization_Plastic surgery EGH - Coded 2 manipulated (2).xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# --- 2) Ensure date column is a datetime ----------------------------------\n",
    "df['First Date of Surgery'] = pd.to_datetime(df['First Date of Surgery'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['First Date of Surgery']).copy()\n",
    "\n",
    "# --- 3) Biweekly bucketing (14-day periods) -------------------------------\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# Anchor to earliest surgery date\n",
    "start_date = df['First Date of Surgery'].min().normalize()\n",
    "\n",
    "# Integer biweek index\n",
    "df['biweek_idx'] = ((df['First Date of Surgery'] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# --- 4) Aggregate injury types by biweek ----------------------------------\n",
    "biweekly_injury_counts = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Create readable date ranges\n",
    "biweekly_injury_counts['period_start'] = start_date + pd.to_timedelta(\n",
    "    biweekly_injury_counts['biweek_idx'] * 14, unit='D'\n",
    ")\n",
    "biweekly_injury_counts['period_end'] = (\n",
    "    biweekly_injury_counts['period_start'] + pd.to_timedelta(13, unit='D')\n",
    ")\n",
    "\n",
    "biweekly_injury_counts['period'] = (\n",
    "    biweekly_injury_counts['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly_injury_counts['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "final_df_EGH_summary = biweekly_injury_counts[['period'] + injury_columns].copy()\n",
    "\n",
    "# --- 5) Save output --------------------------------------------------------\n",
    "out_path = \"biweekly_injury_aggregates_EGH.xlsx\"\n",
    "final_df_EGH_summary.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"Saved aggregated file to:\", out_path)\n",
    "print(final_df_EGH_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e0708",
   "metadata": {},
   "source": [
    "Shifa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a17f489",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1) Load file ---------------------------------------------------------\n",
    "file_path = \"plastic file Shifa 2_injurycategorization(Sheet1).csv\"\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    raise FileNotFoundError(f\"File not found: {file_path!r}\")\n",
    "\n",
    "# read csv (DO NOT pass openpyxl engine here)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2) Ensure date column is a datetime ----------------------------------\n",
    "date_col = 'date of admission'   # keep exactly as in CSV header\n",
    "\n",
    "if date_col not in df.columns:\n",
    "    raise KeyError(f\"Date column {date_col!r} not found in file. Columns found: {list(df.columns)}\")\n",
    "\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=[date_col]).copy()\n",
    "\n",
    "# --- 3) Biweekly bucketing (14-day periods) -------------------------------\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# Check which injury columns are present and warn about missing ones\n",
    "missing = [c for c in injury_columns if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: these injury columns are missing from the CSV and will be treated as zeros: {missing}\")\n",
    "    # add missing columns as zeros so aggregation still works\n",
    "    for c in missing:\n",
    "        df[c] = 0\n",
    "\n",
    "# Convert injury columns to numeric (coerce non-numeric to zeros)\n",
    "for c in injury_columns:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Anchor to earliest surgery/admission date\n",
    "start_date = df[date_col].min().normalize()\n",
    "\n",
    "# Integer biweek index (0-based)\n",
    "df['biweek_idx'] = ((df[date_col] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# --- 4) Aggregate injury types by biweek ----------------------------------\n",
    "biweekly_injury_counts = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Create readable date ranges\n",
    "biweekly_injury_counts['period_start'] = start_date + pd.to_timedelta(\n",
    "    biweekly_injury_counts['biweek_idx'] * 14, unit='D'\n",
    ")\n",
    "biweekly_injury_counts['period_end'] = (\n",
    "    biweekly_injury_counts['period_start'] + pd.to_timedelta(13, unit='D')\n",
    ")\n",
    "\n",
    "biweekly_injury_counts['period'] = (\n",
    "    biweekly_injury_counts['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly_injury_counts['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "final_df_shifa_summary = biweekly_injury_counts[['period'] + injury_columns].copy()\n",
    "\n",
    "# --- 5) Save output --------------------------------------------------------\n",
    "out_path = \"biweekly_injury_aggregates_shifa.xlsx\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "final_df_shifa_summary.to_excel(out_path, index=False)\n",
    "print(\"Saved aggregated file to:\", out_path)\n",
    "print(final_df_shifa_summary.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d717d",
   "metadata": {},
   "source": [
    "Aggregate Nasser, Shifa, EGH Injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a59aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- User-editable file paths --------------------------------\n",
    "path1 = \"biweekly_injury_aggregates_OT.xlsx\"\n",
    "path2 = \"biweekly_injury_aggregates_EGH.xlsx\"\n",
    "path3 = \"biweekly_injury_aggregates_shifa.xlsx\"\n",
    "\n",
    "out_combined = \"combined_biweekly_injury_aggregates_no_prefix.xlsx\"\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def load_period_table(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    df = pd.read_excel(path).copy()\n",
    "\n",
    "    # Normalize period_start / period_end from several possible formats\n",
    "    if 'period_start' in df.columns:\n",
    "        df['period_start'] = pd.to_datetime(df['period_start'])\n",
    "        if 'period_end' not in df.columns:\n",
    "            df['period_end'] = df['period_start'] + pd.Timedelta(days=13)\n",
    "    elif 'period' in df.columns:\n",
    "        # Expect \"YYYY-MM-DD to YYYY-MM-DD\"\n",
    "        def parse_period(s):\n",
    "            if pd.isna(s):\n",
    "                return (pd.NaT, pd.NaT)\n",
    "            s = str(s)\n",
    "            if ' to ' in s:\n",
    "                left, right = s.split(' to ', 1)\n",
    "                return (pd.to_datetime(left), pd.to_datetime(right))\n",
    "            # fallback: try single date\n",
    "            d = pd.to_datetime(s, errors='coerce')\n",
    "            if pd.isna(d):\n",
    "                return (pd.NaT, pd.NaT)\n",
    "            return (d, d + pd.Timedelta(days=13))\n",
    "\n",
    "        parsed = df['period'].astype(str).apply(parse_period)\n",
    "        df[['period_start', 'period_end']] = pd.DataFrame(parsed.tolist(), index=df.index)\n",
    "    elif 'year_month' in df.columns:\n",
    "        # fallback monthly -> treat as first-of-month as period_start\n",
    "        df['period_start'] = pd.to_datetime(df['year_month'].astype(str) + '-01', errors='coerce')\n",
    "        df['period_end'] = df['period_start'] + pd.Timedelta(days=13)\n",
    "    else:\n",
    "        raise KeyError(f\"No recognizable period column in {path}. Found columns: {list(df.columns)}\")\n",
    "\n",
    "    # Create canonical period string\n",
    "    df['period'] = df['period_start'].dt.strftime('%Y-%m-%d') + ' to ' + df['period_end'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Identify injury columns: numeric columns excluding period fields\n",
    "    exclude = {'period', 'period_start', 'period_end', 'year_month', 'biweek_idx'}\n",
    "    injury_cols = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # If none found, try common names\n",
    "    if not injury_cols:\n",
    "        possible = ['Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'CMF', 'NTD']\n",
    "        injury_cols = [c for c in possible if c in df.columns]\n",
    "\n",
    "    if not injury_cols:\n",
    "        raise ValueError(f\"No injury-like numeric columns detected in {path}. Columns: {list(df.columns)}\")\n",
    "\n",
    "    # Ensure numeric\n",
    "    for c in injury_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Keep only period_start/end/period + injury cols for merging\n",
    "    keep = ['period_start', 'period_end', 'period'] + injury_cols\n",
    "    return df[keep], df  # normalized + original\n",
    "\n",
    "\n",
    "# Load all three (normalized + original)\n",
    "norm1, orig1 = load_period_table(path1)\n",
    "norm2, orig2 = load_period_table(path2)\n",
    "norm3, orig3 = load_period_table(path3)\n",
    "\n",
    "# Determine the union of all injury columns\n",
    "all_injuries = sorted(\n",
    "    set(norm1.columns.tolist()[3:] + norm2.columns.tolist()[3:] + norm3.columns.tolist()[3:])\n",
    ")\n",
    "\n",
    "# Ensure each normalized DF has all injury columns (fill missing with zeros)\n",
    "def ensure_cols(df, cols):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0\n",
    "    # keep ordering: period_start, period_end, period, then injuries\n",
    "    return df[['period_start', 'period_end', 'period'] + cols].copy()\n",
    "\n",
    "norm1 = ensure_cols(norm1, all_injuries)\n",
    "norm2 = ensure_cols(norm2, all_injuries)\n",
    "norm3 = ensure_cols(norm3, all_injuries)\n",
    "\n",
    "# ---- IMPORTANT: do NOT attempt to merge the three wide tables directly (overlapping columns).\n",
    "# Instead, concatenate them and groupby period to SUM counts across inputs.\n",
    "concat = pd.concat([norm1, norm2, norm3], ignore_index=True)\n",
    "\n",
    "# Group and sum numeric injury columns by the canonical period\n",
    "agg = concat.groupby(['period_start', 'period_end', 'period'], as_index=False)[all_injuries].sum()\n",
    "\n",
    "# Sort by period_start\n",
    "agg = agg.sort_values('period_start').reset_index(drop=True)\n",
    "\n",
    "# Save combined and originals to Excel\n",
    "with pd.ExcelWriter(out_combined, engine='openpyxl') as writer:\n",
    "    agg.to_excel(writer, sheet_name='Combined', index=False)\n",
    "    orig1.to_excel(writer, sheet_name='Original_1', index=False)\n",
    "    orig2.to_excel(writer, sheet_name='Original_2', index=False)\n",
    "    orig3.to_excel(writer, sheet_name='Original_3', index=False)\n",
    "\n",
    "print(\"Saved combined workbook to:\", out_combined)\n",
    "print(agg.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
