{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c315ac09",
   "metadata": {},
   "source": [
    "OT Summary (Nasser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0920b0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     period  CMF  Burn  Limb  Soft Tissue  Wound Care  NTD\n",
      "0  2024-11-11 to 2024-11-24  0.0    19    78          133          84  0.0\n",
      "1  2024-11-25 to 2024-12-08  0.0    16    75          120          73  0.0\n",
      "2  2024-12-09 to 2024-12-22  0.0     8    57          122         104  0.0\n",
      "3  2024-12-23 to 2025-01-05  0.0    22    56          120         114  0.0\n",
      "4  2025-01-06 to 2025-01-19  0.0    32    55          119         134  0.0\n",
      "5  2025-01-20 to 2025-02-02  0.0    34    44          148         133  0.0\n",
      "Saved aggregated file to: biweekly_injury_aggregates_OT.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = \"Update2_Injury_Categorization_OT.summary.20-Apr-2025 2.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# keep your original cleaning\n",
    "df['Date of Surgical Encounter'] = pd.to_datetime(df['Date of Surgical Encounter'], errors='coerce')\n",
    "df = df.dropna(subset=['Date of Surgical Encounter']).copy()\n",
    "\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# ---------------- Biweekly bucketing anchored to first date ----------------\n",
    "# Anchor start to the earliest date (normalized to midnight)\n",
    "start_date = df['Date of Surgical Encounter'].min().normalize()\n",
    "\n",
    "# compute integer biweek index (0 = first 14-day period starting at start_date)\n",
    "df['biweek_idx'] = ((df['Date of Surgical Encounter'] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# aggregate by biweek index\n",
    "biweekly = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# create readable start/end labels for each biweek\n",
    "biweekly['period_start'] = start_date + pd.to_timedelta(biweekly['biweek_idx'] * 14, unit='D')\n",
    "biweekly['period_end'] = biweekly['period_start'] + pd.to_timedelta(13, unit='D')\n",
    "\n",
    "# human-friendly label (change format if you prefer)\n",
    "biweekly['period'] = (\n",
    "    biweekly['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "# final dataframe with period first, then injury columns\n",
    "final_df_OT_summary = biweekly[['period'] + injury_columns].copy()\n",
    "\n",
    "# optional: sort by period (already in order because biweek_idx increases)\n",
    "final_df_OT_summary = final_df_OT_summary.sort_values('period').reset_index(drop=True)\n",
    "\n",
    "print(final_df_OT_summary)\n",
    "\n",
    "out_path = \"biweekly_injury_aggregates_OT.xlsx\"\n",
    "final_df_OT_summary.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"Saved aggregated file to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82542bb6",
   "metadata": {},
   "source": [
    "EGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00e5df96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggregated file to: biweekly_injury_aggregates_EGH.xlsx\n",
      "                     period  CMF  Burn  Limb  Soft Tissue  Wound Care  NTD\n",
      "0  2023-12-11 to 2023-12-24  0.0   0.0   1.0          1.0         1.0  0.0\n",
      "1  2024-01-08 to 2024-01-21  0.0   0.0   2.0          2.0         2.0  0.0\n",
      "2  2024-01-22 to 2024-02-04  0.0   0.0   6.0          6.0         6.0  0.0\n",
      "3  2024-02-05 to 2024-02-18  2.0   1.0   6.0          6.0         7.0  0.0\n",
      "4  2024-02-19 to 2024-03-03  0.0   0.0   5.0          4.0         4.0  0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- 1) Load file ---------------------------------------------------------\n",
    "file_path = \"InjuryCategorization_Plastic surgery EGH - Coded 2 manipulated.xlsx\"\n",
    "df = pd.read_excel(file_path, engine='openpyxl')\n",
    "\n",
    "# --- 2) Ensure date column is a datetime ----------------------------------\n",
    "df['First Date of Surgery'] = pd.to_datetime(df['First Date of Surgery'], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=['First Date of Surgery']).copy()\n",
    "\n",
    "# --- 3) Biweekly bucketing (14-day periods) -------------------------------\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# Anchor to earliest surgery date\n",
    "start_date = df['First Date of Surgery'].min().normalize()\n",
    "\n",
    "# Integer biweek index\n",
    "df['biweek_idx'] = ((df['First Date of Surgery'] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# --- 4) Aggregate injury types by biweek ----------------------------------\n",
    "biweekly_injury_counts = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Create readable date ranges\n",
    "biweekly_injury_counts['period_start'] = start_date + pd.to_timedelta(\n",
    "    biweekly_injury_counts['biweek_idx'] * 14, unit='D'\n",
    ")\n",
    "biweekly_injury_counts['period_end'] = (\n",
    "    biweekly_injury_counts['period_start'] + pd.to_timedelta(13, unit='D')\n",
    ")\n",
    "\n",
    "biweekly_injury_counts['period'] = (\n",
    "    biweekly_injury_counts['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly_injury_counts['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "final_df_EGH_summary = biweekly_injury_counts[['period'] + injury_columns].copy()\n",
    "\n",
    "# --- 5) Save output --------------------------------------------------------\n",
    "out_path = \"biweekly_injury_aggregates_EGH.xlsx\"\n",
    "final_df_EGH_summary.to_excel(out_path, index=False)\n",
    "\n",
    "print(\"Saved aggregated file to:\", out_path)\n",
    "print(final_df_EGH_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203e0708",
   "metadata": {},
   "source": [
    "Shifa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a17f489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved aggregated file to: biweekly_injury_aggregates_shifa.xlsx\n",
      "                     period  CMF  Burn  Limb  Soft Tissue  Wound Care  NTD\n",
      "0  2023-10-07 to 2023-10-20    1    37    11           44           0    0\n",
      "1  2023-10-21 to 2023-11-03    3    15     1           16           1    0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- 1) Load file ---------------------------------------------------------\n",
    "file_path = \"plastic file Shifa 2_injurycategorization(Sheet1).csv\"\n",
    "\n",
    "if not Path(file_path).exists():\n",
    "    raise FileNotFoundError(f\"File not found: {file_path!r}\")\n",
    "\n",
    "# read csv (DO NOT pass openpyxl engine here)\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# --- 2) Ensure date column is a datetime ----------------------------------\n",
    "date_col = 'date of admission'   # keep exactly as in CSV header\n",
    "\n",
    "if date_col not in df.columns:\n",
    "    raise KeyError(f\"Date column {date_col!r} not found in file. Columns found: {list(df.columns)}\")\n",
    "\n",
    "df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "\n",
    "# Drop rows with invalid dates\n",
    "df = df.dropna(subset=[date_col]).copy()\n",
    "\n",
    "# --- 3) Biweekly bucketing (14-day periods) -------------------------------\n",
    "injury_columns = ['CMF', 'Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'NTD']\n",
    "\n",
    "# Check which injury columns are present and warn about missing ones\n",
    "missing = [c for c in injury_columns if c not in df.columns]\n",
    "if missing:\n",
    "    print(f\"Warning: these injury columns are missing from the CSV and will be treated as zeros: {missing}\")\n",
    "    # add missing columns as zeros so aggregation still works\n",
    "    for c in missing:\n",
    "        df[c] = 0\n",
    "\n",
    "# Convert injury columns to numeric (coerce non-numeric to zeros)\n",
    "for c in injury_columns:\n",
    "    df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Anchor to earliest surgery/admission date\n",
    "start_date = df[date_col].min().normalize()\n",
    "\n",
    "# Integer biweek index (0-based)\n",
    "df['biweek_idx'] = ((df[date_col] - start_date).dt.days // 14).astype(int)\n",
    "\n",
    "# --- 4) Aggregate injury types by biweek ----------------------------------\n",
    "biweekly_injury_counts = (\n",
    "    df.groupby('biweek_idx')[injury_columns]\n",
    "      .sum()\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Create readable date ranges\n",
    "biweekly_injury_counts['period_start'] = start_date + pd.to_timedelta(\n",
    "    biweekly_injury_counts['biweek_idx'] * 14, unit='D'\n",
    ")\n",
    "biweekly_injury_counts['period_end'] = (\n",
    "    biweekly_injury_counts['period_start'] + pd.to_timedelta(13, unit='D')\n",
    ")\n",
    "\n",
    "biweekly_injury_counts['period'] = (\n",
    "    biweekly_injury_counts['period_start'].dt.strftime('%Y-%m-%d')\n",
    "    + ' to '\n",
    "    + biweekly_injury_counts['period_end'].dt.strftime('%Y-%m-%d')\n",
    ")\n",
    "\n",
    "final_df_shifa_summary = biweekly_injury_counts[['period'] + injury_columns].copy()\n",
    "\n",
    "# --- 5) Save output --------------------------------------------------------\n",
    "out_path = \"biweekly_injury_aggregates_shifa.xlsx\"\n",
    "\n",
    "\n",
    "final_df_shifa_summary.to_excel(out_path, index=False)\n",
    "print(\"Saved aggregated file to:\", out_path)\n",
    "print(final_df_shifa_summary.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3d717d",
   "metadata": {},
   "source": [
    "Aggregate Nasser, Shifa, EGH Injuries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a59aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined workbook to: combined_biweekly_injury_aggregates_no_prefix.xlsx\n",
      "   period_start period_end                    period  Burn  CMF  Limb  NTD  \\\n",
      "0    2023-10-07 2023-10-20  2023-10-07 to 2023-10-20    37    1    11    0   \n",
      "1    2023-10-21 2023-11-03  2023-10-21 to 2023-11-03    15    3     1    0   \n",
      "2    2023-12-11 2023-12-24  2023-12-11 to 2023-12-24     0    0     1    0   \n",
      "3    2024-01-08 2024-01-21  2024-01-08 to 2024-01-21     0    0     2    0   \n",
      "4    2024-01-22 2024-02-04  2024-01-22 to 2024-02-04     0    0     6    0   \n",
      "5    2024-02-05 2024-02-18  2024-02-05 to 2024-02-18     1    2     6    0   \n",
      "6    2024-02-19 2024-03-03  2024-02-19 to 2024-03-03     0    0     5    0   \n",
      "7    2024-03-04 2024-03-17  2024-03-04 to 2024-03-17     1    2     8    1   \n",
      "8    2024-03-18 2024-03-31  2024-03-18 to 2024-03-31     1    3     7    0   \n",
      "9    2024-04-01 2024-04-14  2024-04-01 to 2024-04-14     3    0     7    0   \n",
      "10   2024-04-15 2024-04-28  2024-04-15 to 2024-04-28     2    0     1    0   \n",
      "11   2024-11-11 2024-11-24  2024-11-11 to 2024-11-24    19    0    78    0   \n",
      "12   2024-11-25 2024-12-08  2024-11-25 to 2024-12-08    16    0    75    0   \n",
      "13   2024-12-09 2024-12-22  2024-12-09 to 2024-12-22     8    0    57    0   \n",
      "14   2024-12-23 2025-01-05  2024-12-23 to 2025-01-05    22    0    56    0   \n",
      "15   2025-01-06 2025-01-19  2025-01-06 to 2025-01-19    32    0    55    0   \n",
      "16   2025-01-20 2025-02-02  2025-01-20 to 2025-02-02    34    0    44    0   \n",
      "\n",
      "    Soft Tissue  Wound Care  \n",
      "0            44           0  \n",
      "1            16           1  \n",
      "2             1           1  \n",
      "3             2           2  \n",
      "4             6           6  \n",
      "5             6           7  \n",
      "6             4           4  \n",
      "7             8           7  \n",
      "8             9           3  \n",
      "9             8           8  \n",
      "10            2           3  \n",
      "11          133          84  \n",
      "12          120          73  \n",
      "13          122         104  \n",
      "14          120         114  \n",
      "15          119         134  \n",
      "16          148         133  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# ---------------- User-editable file paths --------------------------------\n",
    "path1 = \"biweekly_injury_aggregates_OT.xlsx\"\n",
    "path2 = \"biweekly_injury_aggregates_EGH.xlsx\"\n",
    "path3 = \"biweekly_injury_aggregates_shifa.xlsx\"\n",
    "\n",
    "out_combined = \"combined_biweekly_injury_aggregates_no_prefix.xlsx\"\n",
    "# --------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def load_period_table(path):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "\n",
    "    df = pd.read_excel(path).copy()\n",
    "\n",
    "    # Normalize period_start / period_end from several possible formats\n",
    "    if 'period_start' in df.columns:\n",
    "        df['period_start'] = pd.to_datetime(df['period_start'])\n",
    "        if 'period_end' not in df.columns:\n",
    "            df['period_end'] = df['period_start'] + pd.Timedelta(days=13)\n",
    "    elif 'period' in df.columns:\n",
    "        # Expect \"YYYY-MM-DD to YYYY-MM-DD\"\n",
    "        def parse_period(s):\n",
    "            if pd.isna(s):\n",
    "                return (pd.NaT, pd.NaT)\n",
    "            s = str(s)\n",
    "            if ' to ' in s:\n",
    "                left, right = s.split(' to ', 1)\n",
    "                return (pd.to_datetime(left), pd.to_datetime(right))\n",
    "            # fallback: try single date\n",
    "            d = pd.to_datetime(s, errors='coerce')\n",
    "            if pd.isna(d):\n",
    "                return (pd.NaT, pd.NaT)\n",
    "            return (d, d + pd.Timedelta(days=13))\n",
    "\n",
    "        parsed = df['period'].astype(str).apply(parse_period)\n",
    "        df[['period_start', 'period_end']] = pd.DataFrame(parsed.tolist(), index=df.index)\n",
    "    elif 'year_month' in df.columns:\n",
    "        # fallback monthly -> treat as first-of-month as period_start\n",
    "        df['period_start'] = pd.to_datetime(df['year_month'].astype(str) + '-01', errors='coerce')\n",
    "        df['period_end'] = df['period_start'] + pd.Timedelta(days=13)\n",
    "    else:\n",
    "        raise KeyError(f\"No recognizable period column in {path}. Found columns: {list(df.columns)}\")\n",
    "\n",
    "    # Create canonical period string\n",
    "    df['period'] = df['period_start'].dt.strftime('%Y-%m-%d') + ' to ' + df['period_end'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Identify injury columns: numeric columns excluding period fields\n",
    "    exclude = {'period', 'period_start', 'period_end', 'year_month', 'biweek_idx'}\n",
    "    injury_cols = [c for c in df.columns if c not in exclude and pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # If none found, try common names\n",
    "    if not injury_cols:\n",
    "        possible = ['Burn', 'Limb', 'Soft Tissue', 'Wound Care', 'CMF', 'NTD']\n",
    "        injury_cols = [c for c in possible if c in df.columns]\n",
    "\n",
    "    if not injury_cols:\n",
    "        raise ValueError(f\"No injury-like numeric columns detected in {path}. Columns: {list(df.columns)}\")\n",
    "\n",
    "    # Ensure numeric\n",
    "    for c in injury_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Keep only period_start/end/period + injury cols for merging\n",
    "    keep = ['period_start', 'period_end', 'period'] + injury_cols\n",
    "    return df[keep], df  # normalized + original\n",
    "\n",
    "\n",
    "# Load all three (normalized + original)\n",
    "norm1, orig1 = load_period_table(path1)\n",
    "norm2, orig2 = load_period_table(path2)\n",
    "norm3, orig3 = load_period_table(path3)\n",
    "\n",
    "# Determine the union of all injury columns\n",
    "all_injuries = sorted(\n",
    "    set(norm1.columns.tolist()[3:] + norm2.columns.tolist()[3:] + norm3.columns.tolist()[3:])\n",
    ")\n",
    "\n",
    "# Ensure each normalized DF has all injury columns (fill missing with zeros)\n",
    "def ensure_cols(df, cols):\n",
    "    for c in cols:\n",
    "        if c not in df.columns:\n",
    "            df[c] = 0\n",
    "    # keep ordering: period_start, period_end, period, then injuries\n",
    "    return df[['period_start', 'period_end', 'period'] + cols].copy()\n",
    "\n",
    "norm1 = ensure_cols(norm1, all_injuries)\n",
    "norm2 = ensure_cols(norm2, all_injuries)\n",
    "norm3 = ensure_cols(norm3, all_injuries)\n",
    "\n",
    "# ---- IMPORTANT: do NOT attempt to merge the three wide tables directly (overlapping columns).\n",
    "# Instead, concatenate them and groupby period to SUM counts across inputs.\n",
    "concat = pd.concat([norm1, norm2, norm3], ignore_index=True)\n",
    "\n",
    "# Group and sum numeric injury columns by the canonical period\n",
    "agg = concat.groupby(['period_start', 'period_end', 'period'], as_index=False)[all_injuries].sum()\n",
    "\n",
    "# Sort by period_start\n",
    "agg = agg.sort_values('period_start').reset_index(drop=True)\n",
    "\n",
    "# Save combined and originals to Excel\n",
    "with pd.ExcelWriter(out_combined, engine='openpyxl') as writer:\n",
    "    agg.to_excel(writer, sheet_name='Combined', index=False)\n",
    "    orig1.to_excel(writer, sheet_name='Original_1', index=False)\n",
    "    orig2.to_excel(writer, sheet_name='Original_2', index=False)\n",
    "    orig3.to_excel(writer, sheet_name='Original_3', index=False)\n",
    "\n",
    "print(\"Saved combined workbook to:\", out_combined)\n",
    "print(agg.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
