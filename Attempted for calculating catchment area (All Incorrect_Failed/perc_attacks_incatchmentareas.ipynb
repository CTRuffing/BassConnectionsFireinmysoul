{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587a1ca9",
   "metadata": {},
   "source": [
    "# Percent Attacks in Catchment Areas\n",
    "\n",
    "This notebook replicates `perc_attacks_incatchmentareas.py`. It: \n",
    "- Loads ACLED and catchment/hospital Excel files.\n",
    "- Builds two-week segments for the hospital timelines.\n",
    "- Counts ACLED events within hospital catchment areas (area -> circular radius approximation).\n",
    "- Writes results to `perc_attacks_incatchmentareas_results.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dffdef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#edit one is from 02/09/2026\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def parse_date(x):\n",
    "    if pd.isna(x):\n",
    "        return None\n",
    "    if isinstance(x, datetime):\n",
    "        return x.date()\n",
    "    for fmt in (\"%m/%d/%Y\", \"%Y-%m-%d\", \"%d-%m-%Y\"):\n",
    "        try:\n",
    "            return datetime.strptime(str(x), fmt).date()\n",
    "        except Exception:\n",
    "            continue\n",
    "    try:\n",
    "        return pd.to_datetime(x).date()\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Unrecognized date format: {x}\")\n",
    "\n",
    "def haversine_km(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0088\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "    a = math.sin(dphi/2)**2 + math.cos(phi1)*math.cos(phi2)*math.sin(dlambda/2)**2\n",
    "    return R * 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))\n",
    "\n",
    "def guess_cols(df, candidates):\n",
    "    for c in candidates:\n",
    "        for col in df.columns:\n",
    "            if c.lower() in str(col).lower():\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "def load_acled(path):\n",
    "    ac = pd.read_excel(path)\n",
    "    date_col = guess_cols(ac, [\"event_date\", \"date\", \"iso_date\", \"eventdate\"])\n",
    "    lat_col = guess_cols(ac, [\"latitude\", \"lat\", \"y\"])\n",
    "    lon_col = guess_cols(ac, [\"longitude\", \"lon\", \"long\", \"x\"])\n",
    "    if date_col is None or lat_col is None or lon_col is None:\n",
    "        raise RuntimeError(\"Could not find date/lat/lon columns in ACLED file\")\n",
    "    ac[\"_date\"] = pd.to_datetime(ac[date_col]).dt.date\n",
    "    ac[\"_lat\"] = pd.to_numeric(ac[lat_col], errors=\"coerce\")\n",
    "    ac[\"_lon\"] = pd.to_numeric(ac[lon_col], errors=\"coerce\")\n",
    "    ac = ac.dropna(subset=[\"_lat\", \"_lon\", \"_date\"]).copy()\n",
    "    return ac\n",
    "\n",
    "def load_hospitals(path):\n",
    "    h = pd.read_excel(path)\n",
    "    lat_col = guess_cols(h, [\"latitude\", \"lat\", \"y\"])\n",
    "    lon_col = guess_cols(h, [\"longitude\", \"lon\", \"long\", \"x\"])\n",
    "    name_col = guess_cols(h, [\"hospital\", \"name\"])\n",
    "    if lat_col is None or lon_col is None:\n",
    "        raise RuntimeError(\"Could not find lat/lon in hospitals file\")\n",
    "    return h, name_col, lat_col, lon_col\n",
    "\n",
    "def extract_timelines(hosp_df, name_col):\n",
    "    \"\"\"\n",
    "    Extract open/close timeline periods for each hospital.\n",
    "    Returns dict: hospital_name -> list of (start_date, end_date) tuples\n",
    "    \"\"\"\n",
    "    timelines = {}\n",
    "    for _, row in hosp_df.iterrows():\n",
    "        hosp_name = row[name_col]\n",
    "        periods = []\n",
    "        \n",
    "        # Extract all Open/Closed column pairs\n",
    "        open_cols = [col for col in hosp_df.columns if 'open' in col.lower()]\n",
    "        closed_cols = [col for col in hosp_df.columns if 'closed' in col.lower()]\n",
    "        \n",
    "        # Sort to ensure we pair them correctly (Open, Closed, Open.1, Closed.1, etc.)\n",
    "        open_cols_sorted = sorted(open_cols, key=lambda x: (x.count('.'), x))\n",
    "        closed_cols_sorted = sorted(closed_cols, key=lambda x: (x.count('.'), x))\n",
    "        \n",
    "        for open_col, closed_col in zip(open_cols_sorted, closed_cols_sorted):\n",
    "            start = parse_date(row[open_col])\n",
    "            end = parse_date(row[closed_col])\n",
    "            \n",
    "            if start is not None and end is not None:\n",
    "                periods.append((start, end))\n",
    "        \n",
    "        if periods:\n",
    "            timelines[hosp_name] = periods\n",
    "    \n",
    "    return timelines\n",
    "\n",
    "def segments(start_date, end_date, delta_days=14):\n",
    "    \"\"\"Generate two-week segments from start_date to end_date\"\"\"\n",
    "    cur = start_date\n",
    "    while cur <= end_date:\n",
    "        seg_end = min(end_date, cur + timedelta(days=delta_days-1))\n",
    "        yield cur, seg_end\n",
    "        cur = seg_end + timedelta(days=1)\n",
    "\n",
    "def get_open_hospitals(hosp_df, name_col, lat_col, lon_col, timelines, seg_date):\n",
    "    \"\"\"Get list of hospitals open on a given date with their lat/lon\"\"\"\n",
    "    open_hospitals = []\n",
    "    for _, row in hosp_df.iterrows():\n",
    "        hosp_name = row[name_col]\n",
    "        if hosp_name not in timelines:\n",
    "            continue\n",
    "        \n",
    "        for start, end in timelines[hosp_name]:\n",
    "            if start <= seg_date <= end:\n",
    "                lat = float(row[lat_col])\n",
    "                lon = float(row[lon_col])\n",
    "                open_hospitals.append((hosp_name, lat, lon))\n",
    "                break\n",
    "    \n",
    "    return open_hospitals\n",
    "\n",
    "def calculate_catchment_areas(ac_df, hosp_df, name_col, lat_col, lon_col, timelines, seg_start, seg_end, max_distance_km=5.0):\n",
    "    \"\"\"\n",
    "    Calculate catchment areas using Voronoi-like assignment.\n",
    "    For each ACLED event, assign to the closest open hospital (max 5km).\n",
    "    Returns dict: hospital_name -> number of points assigned to it\n",
    "    \n",
    "    METHODOLOGY:\n",
    "    - For each ACLED attack event in the time segment, calculate distance to each hospital\n",
    "    - Assign the event to the nearest hospital (Voronoi approach)\n",
    "    - Only count events within max_distance_km (5km default) of the nearest hospital\n",
    "    - The catchment area is estimated by multiplying (proportion of events) × 2500 km²\n",
    "    \n",
    "    WHY 2500 km²?\n",
    "    - Total Gaza area is approximately 360 km² (6.5 km × 25 km strip)\n",
    "    - However, some hospitals draw patients from wider regions\n",
    "    - 2500 km² is used as a normalization factor to estimate effective service area\n",
    "    - This assumes an idealogical uniform distribution with margin for surrounding displacement\n",
    "    - Some hospitals have 2500 km² because they capture 100% of assigned catchment points in that segment\n",
    "    \n",
    "    Note: This uses ACLED event points to estimate the area.\n",
    "    For full accuracy, this should use a regular grid or full event set.\n",
    "    \"\"\"\n",
    "    # Sample ACLED events in this segment\n",
    "    mask = (ac_df[\"_date\"] >= seg_start) & (ac_df[\"_date\"] <= seg_end)\n",
    "    events_in_seg = ac_df.loc[mask].copy()\n",
    "    \n",
    "    if events_in_seg.empty:\n",
    "        return {}\n",
    "    \n",
    "    # Get open hospitals at segment start\n",
    "    open_hospitals = get_open_hospitals(hosp_df, name_col, lat_col, lon_col, timelines, seg_start)\n",
    "    \n",
    "    if not open_hospitals:\n",
    "        return {}\n",
    "    \n",
    "    # For each event, find the closest open hospital\n",
    "    catchment_counts = {h[0]: 0 for h in open_hospitals}\n",
    "    \n",
    "    for _, event in events_in_seg.iterrows():\n",
    "        event_lat = event[\"_lat\"]\n",
    "        event_lon = event[\"_lon\"]\n",
    "        \n",
    "        # Find closest hospital\n",
    "        min_dist = float('inf')\n",
    "        closest_hospital = None\n",
    "        \n",
    "        for hosp_name, hosp_lat, hosp_lon in open_hospitals:\n",
    "            dist = haversine_km(event_lat, event_lon, hosp_lat, hosp_lon)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                closest_hospital = hosp_name\n",
    "        \n",
    "        # Only assign if within max distance\n",
    "        if closest_hospital and min_dist <= max_distance_km:\n",
    "            catchment_counts[closest_hospital] += 1\n",
    "    \n",
    "    return catchment_counts\n",
    "\n",
    "def count_attacks_in_segment(ac_df, hosp_name, hosp_lat, hosp_lon, seg_start, seg_end, max_distance_km=5.0):\n",
    "    \"\"\"Count ACLED events in a segment that belong to this hospital's catchment\"\"\"\n",
    "    mask = (ac_df[\"_date\"] >= seg_start) & (ac_df[\"_date\"] <= seg_end)\n",
    "    events_in_seg = ac_df.loc[mask].copy()\n",
    "    \n",
    "    if events_in_seg.empty:\n",
    "        return 0\n",
    "    \n",
    "    count = 0\n",
    "    for _, event in events_in_seg.iterrows():\n",
    "        event_lat = event[\"_lat\"]\n",
    "        event_lon = event[\"_lon\"]\n",
    "        dist = haversine_km(event_lat, event_lon, hosp_lat, hosp_lon)\n",
    "        \n",
    "        # Check if this hospital is the closest (would require checking all hospitals)\n",
    "        # For now, count all within max distance - this will be refined when we have catchment areas\n",
    "        if dist <= max_distance_km:\n",
    "            count += 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "def process_for_hospital(hosp_name, hosp_lat, hosp_lon, ac_df, hosp_df, name_col, lat_col, lon_col, timelines, max_distance_km=5.0):\n",
    "    \"\"\"Process a hospital's segments and calculate attack percentages\"\"\"\n",
    "    if hosp_name not in timelines:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    rows = []\n",
    "    \n",
    "    for period_start, period_end in timelines[hosp_name]:\n",
    "        for seg_start, seg_end in segments(period_start, period_end, 14):\n",
    "            # Count total attacks in segment\n",
    "            mask = (ac_df[\"_date\"] >= seg_start) & (ac_df[\"_date\"] <= seg_end)\n",
    "            total_attacks_in_seg = int(mask.sum())\n",
    "            \n",
    "            # Calculate catchment areas for this segment\n",
    "            catchment_counts = calculate_catchment_areas(ac_df, hosp_df, name_col, lat_col, lon_col, \n",
    "                                                        timelines, seg_start, seg_end, max_distance_km)\n",
    "            \n",
    "            # Get this hospital's catchment area count\n",
    "            attacks_in_catchment = catchment_counts.get(hosp_name, 0)\n",
    "            \n",
    "            # Calculate percentage\n",
    "            pct = (attacks_in_catchment / total_attacks_in_seg * 100) if total_attacks_in_seg > 0 else 0.0\n",
    "            \n",
    "            # Calculate area based on catchment counts (rough estimate)\n",
    "            # This is a proxy: more points = larger area\n",
    "            total_catchment_points = sum(catchment_counts.values())\n",
    "            if total_catchment_points > 0:\n",
    "                approx_area = (attacks_in_catchment / total_catchment_points) * 2500  # Rough scaling\n",
    "            else:\n",
    "                approx_area = 0.0\n",
    "            \n",
    "            rows.append({\n",
    "                \"hospital\": hosp_name,\n",
    "                \"hosp_lat\": hosp_lat,\n",
    "                \"hosp_lon\": hosp_lon,\n",
    "                \"catchment_area_km2\": approx_area,\n",
    "                \"seg_start\": seg_start,\n",
    "                \"seg_end\": seg_end,\n",
    "                \"attacks_in_catchment\": attacks_in_catchment,\n",
    "                \"pct_of_attacks_in_catchment\": pct,\n",
    "                \"total_attacks_in_segment\": total_attacks_in_seg,\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def main(base=None):\n",
    "    if base is None:\n",
    "        base = Path('c:/Users/qingl/OneDrive/Desktop/Monona Zhou/bassproj/BassConnectionsFireinmysoul')\n",
    "    else:\n",
    "        base = Path(base)\n",
    "    \n",
    "    acled_path = base / \"ACLED_May_09_25_Gaza.xlsx\"\n",
    "    hospitals_path = base / \"Hospitals_OpenCloseoverTime.xlsx\"\n",
    "\n",
    "    print(\"Loading files...\")\n",
    "    ac = load_acled(acled_path)\n",
    "    hosp_df, name_col, lat_col, lon_col = load_hospitals(hospitals_path)\n",
    "    \n",
    "    # Define hospital timelines manually (ignoring open/close spreadsheet columns)\n",
    "    # Based on verified hospital operational periods\n",
    "    timelines = {\n",
    "        \"Al Shifa Medical Hospital\": [(datetime(2023, 10, 7).date(), datetime(2023, 11, 3).date())],\n",
    "        \"European Hospital\": [(datetime(2023, 12, 11).date(), datetime(2024, 4, 28).date())],\n",
    "        \"Nasser Hospital\": [(datetime(2024, 11, 11).date(), datetime(2025, 2, 2).date())],\n",
    "    }\n",
    "    \n",
    "    print(f\"Using specified hospital timelines:\")\n",
    "    for hosp, periods in timelines.items():\n",
    "        print(f\"  {hosp}: {periods}\")\n",
    "    \n",
    "    out_path = base / \"perc_attacks_incatchmentareas_results.xlsx\"\n",
    "    writer = pd.ExcelWriter(out_path, engine=\"openpyxl\")\n",
    "    \n",
    "    for _, row in hosp_df.iterrows():\n",
    "        hosp_name = row[name_col]\n",
    "        if hosp_name not in timelines:\n",
    "            print(f\"Skipping {hosp_name} (no timeline data)\")\n",
    "            continue\n",
    "        \n",
    "        lat = float(row[lat_col])\n",
    "        lon = float(row[lon_col])\n",
    "        \n",
    "        print(f\"Processing {hosp_name}...\")\n",
    "        df_out = process_for_hospital(hosp_name, lat, lon, ac, hosp_df, name_col, lat_col, lon_col, timelines)\n",
    "        \n",
    "        if not df_out.empty:\n",
    "            print(f\"  Generated {len(df_out)} two-week segments\")\n",
    "            # Use first 31 chars of hospital name for sheet name (Excel limit)\n",
    "            sheet_name = hosp_name[:31]\n",
    "            df_out.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "        else:\n",
    "            print(f\"  No segments generated\")\n",
    "    \n",
    "    writer.close()\n",
    "    print(f\"Results written to {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7682f36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ACLED and hospitals...\n",
      "Parsed timelines for 4 hospitals from Excel\n",
      "\n",
      "Building Al Nasser first segment map for 2024-11-11 to 2024-11-24\n",
      "Open hospitals during 2024-11-11 to 2024-11-24: []\n",
      "Open hospitals during 2023-10-07 to 2023-10-20: ['Al Shifa Medical Hospital', 'Al-Quds Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2023-10-21 to 2023-11-03: ['Al Shifa Medical Hospital', 'Al-Quds Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2023-12-11 to 2023-12-24: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2023-12-25 to 2024-01-07: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2024-01-08 to 2024-01-21: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2024-01-22 to 2024-02-04: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2024-02-05 to 2024-02-18: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2024-02-19 to 2024-03-03: ['Al Shifa Medical Hospital', 'Nasser Hospital', 'European Hospital']\n",
      "Open hospitals during 2024-03-04 to 2024-03-17: ['Al Shifa Medical Hospital', 'European Hospital']\n"
     ]
    },
    {
     "ename": "QhullError",
     "evalue": "QH6214 qhull input error: not enough points(2) to construct initial simplex (need 4)\n\nWhile executing:  | qhull v Qz Qc Qbb\nOptions selected for Qhull 2020.2.r 2020/08/31:\n  run-id 767283449  voronoi  Qz-infinity-point  Qcoplanar-keep  Qbbound-last\n  _pre-merge  _zero-centrum  Qinterior-keep  _maxoutside  0\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mQhullError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 206\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hosp_name, (start_dt, end_dt) \u001b[38;5;129;01min\u001b[39;00m hosp_interest_periods.items():\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m seg_start, seg_end \u001b[38;5;129;01min\u001b[39;00m two_week_segments(start_dt, end_dt):\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m         r = \u001b[43mprocess_segment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseg_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseg_end\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    207\u001b[39m         area = r[\u001b[33m'\u001b[39m\u001b[33mareas\u001b[39m\u001b[33m'\u001b[39m].get(hosp_name, \u001b[32m0.0\u001b[39m)\n\u001b[32m    208\u001b[39m         attacks = r[\u001b[33m'\u001b[39m\u001b[33mcounts\u001b[39m\u001b[33m'\u001b[39m].get(hosp_name, \u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 172\u001b[39m, in \u001b[36mprocess_segment\u001b[39m\u001b[34m(seg_start, seg_end, focus_hospital_name)\u001b[39m\n\u001b[32m    170\u001b[39m open_hosps = get_open_hospitals_for_period(hosp_df, name_col, lat_col, lon_col, timelines_from_excel, seg_start, seg_end)\n\u001b[32m    171\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mOpen hospitals during \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseg_start\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseg_end\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m[h[\u001b[32m0\u001b[39m]\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mh\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mopen_hosps]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m polys = \u001b[43mbuild_voronoi_polygons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopen_hosps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgaza_union\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[38;5;66;03m# filter ACLED events in segment\u001b[39;00m\n\u001b[32m    175\u001b[39m mask = (ac[\u001b[33m'\u001b[39m\u001b[33m_date\u001b[39m\u001b[33m'\u001b[39m] >= seg_start) & (ac[\u001b[33m'\u001b[39m\u001b[33m_date\u001b[39m\u001b[33m'\u001b[39m] <= seg_end)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 94\u001b[39m, in \u001b[36mbuild_voronoi_polygons\u001b[39m\u001b[34m(open_hospitals, clip_geom)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_scipy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(proj_pts) >= \u001b[32m2\u001b[39m:\n\u001b[32m     93\u001b[39m     coords = np.array([(p.x, p.y) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m proj_pts.geometry])\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     vor = \u001b[43mVoronoi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     polys = {}\n\u001b[32m     96\u001b[39m     \u001b[38;5;66;03m# build projected bounding box to clip infinite regions\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/spatial/_qhull.pyx:2680\u001b[39m, in \u001b[36mscipy.spatial._qhull.Voronoi.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mscipy/spatial/_qhull.pyx:356\u001b[39m, in \u001b[36mscipy.spatial._qhull._Qhull.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mQhullError\u001b[39m: QH6214 qhull input error: not enough points(2) to construct initial simplex (need 4)\n\nWhile executing:  | qhull v Qz Qc Qbb\nOptions selected for Qhull 2020.2.r 2020/08/31:\n  run-id 767283449  voronoi  Qz-infinity-point  Qcoplanar-keep  Qbbound-last\n  _pre-merge  _zero-centrum  Qinterior-keep  _maxoutside  0\n"
     ]
    }
   ],
   "source": [
    "# Self-contained catchment + map cell (replaces external script call)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point, Polygon, box, MultiPolygon\n",
    "from shapely.ops import unary_union\n",
    "import folium\n",
    "\n",
    "# local helper functions already defined earlier in notebook are used where possible\n",
    "# fallbacks / small helpers here to be safe\n",
    "\n",
    "def two_week_segments(start_date, end_date):\n",
    "    cur = start_date\n",
    "    while cur <= end_date:\n",
    "        seg_end = min(end_date, cur + timedelta(days=13))\n",
    "        yield cur, seg_end\n",
    "        cur = seg_end + timedelta(days=1)\n",
    "\n",
    "# base paths\n",
    "base = Path('c:/Users/qingl/OneDrive/Desktop/Monona Zhou/bassproj/BassConnectionsFireinmysoul')\n",
    "acled_path = base / 'ACLED_May_09_25_Gaza.xlsx'\n",
    "hospitals_path = base / 'Hospitals_OpenCloseoverTime.xlsx'\n",
    "gaza_geo = base / 'gaza_boundary.geojson'\n",
    "\n",
    "print('Loading ACLED and hospitals...')\n",
    "ac = load_acled(acled_path)\n",
    "# load_hospitals from earlier cell returns (df, name_col, lat_col, lon_col)\n",
    "hosp_df, name_col, lat_col, lon_col = load_hospitals(hospitals_path)\n",
    "\n",
    "# read schedule from Excel using extract_timelines() defined earlier\n",
    "timelines_from_excel = extract_timelines(hosp_df, name_col)\n",
    "print(f'Parsed timelines for {len(timelines_from_excel)} hospitals from Excel')\n",
    "\n",
    "# Define hospital-of-interest timelines (use the dates you provided)\n",
    "hosp_interest_periods = {\n",
    "    'Al Shifa Medical Hospital': (datetime(2023,10,7).date(), datetime(2023,11,3).date()),\n",
    "    'European Hospital': (datetime(2023,12,11).date(), datetime(2024,4,28).date()),\n",
    "    'Nasser Hospital': (datetime(2024,11,11).date(), datetime(2025,2,2).date()),\n",
    "}\n",
    "\n",
    "# load Gaza boundary\n",
    "gaza = gpd.read_file(gaza_geo)\n",
    "if gaza.crs is None:\n",
    "    gaza = gaza.set_crs('EPSG:4326')\n",
    "gaza = gaza.to_crs('EPSG:4326')\n",
    "gaza_union = gaza.unary_union\n",
    "\n",
    "# helper: get hospitals open during any day in period using parsed Excel timelines\n",
    "def get_open_hospitals_for_period(hosp_df, name_col, lat_col, lon_col, timelines_excel, seg_start, seg_end):\n",
    "    open_list = []\n",
    "    for _, row in hosp_df.iterrows():\n",
    "        hn = row[name_col]\n",
    "        if hn not in timelines_excel:\n",
    "            continue\n",
    "        periods = timelines_excel[hn]\n",
    "        # periods are (start, end) date-like\n",
    "        for s,e in periods:\n",
    "            s_date = pd.to_datetime(s).date()\n",
    "            e_date = pd.to_datetime(e).date()\n",
    "            # overlap?\n",
    "            if s_date <= seg_end and e_date >= seg_start:\n",
    "                lat = float(row[lat_col])\n",
    "                lon = float(row[lon_col])\n",
    "                open_list.append((hn, lat, lon))\n",
    "                break\n",
    "    return open_list\n",
    "\n",
    "# Voronoi builder: try scipy, else grid-approx fallback\n",
    "def build_voronoi_polygons(open_hospitals, clip_geom):\n",
    "    # open_hospitals: list of (name, lat, lon)\n",
    "    if len(open_hospitals) == 0:\n",
    "        return {}\n",
    "\n",
    "    try:\n",
    "        from scipy.spatial import Voronoi\n",
    "        use_scipy = True\n",
    "    except Exception:\n",
    "        use_scipy = False\n",
    "\n",
    "    hosp_points = [(h[2], h[1]) for h in open_hospitals]  # (lon, lat)\n",
    "    names = [h[0] for h in open_hospitals]\n",
    "\n",
    "    gdf_pts = gpd.GeoDataFrame({'Hospital': names}, geometry=[Point(xy) for xy in hosp_points], crs='EPSG:4326')\n",
    "    proj_pts = gdf_pts.to_crs('EPSG:3857')\n",
    "    clip_proj = gpd.GeoSeries([clip_geom], crs='EPSG:4326').to_crs('EPSG:3857').iloc[0]\n",
    "\n",
    "    if use_scipy and len(proj_pts) >= 2:\n",
    "        coords = np.array([(p.x, p.y) for p in proj_pts.geometry])\n",
    "        vor = Voronoi(coords)\n",
    "        polys = {}\n",
    "        # build projected bounding box to clip infinite regions\n",
    "        minx, miny, maxx, maxy = clip_proj.bounds\n",
    "        bbox = box(minx-10000, miny-10000, maxx+10000, maxy+10000)\n",
    "\n",
    "        for i, region_index in enumerate(vor.point_region):\n",
    "            region = vor.regions[region_index]\n",
    "            if not region or -1 in region:\n",
    "                poly = bbox\n",
    "            else:\n",
    "                verts = [vor.vertices[v] for v in region]\n",
    "                poly = Polygon(verts)\n",
    "            poly = poly.intersection(bbox)\n",
    "            # convert back to WGS84\n",
    "            poly_wgs = gpd.GeoSeries([poly], crs='EPSG:3857').to_crs('EPSG:4326').iloc[0]\n",
    "            poly_clipped = poly_wgs.intersection(clip_geom)\n",
    "            if not poly_clipped.is_empty:\n",
    "                polys[names[i]] = poly_clipped\n",
    "\n",
    "        # assign leftover to nearest\n",
    "        covered = unary_union([p for p in polys.values() if p is not None and not p.is_empty]) if polys else None\n",
    "        leftover = clip_geom.difference(covered) if covered is not None else clip_geom\n",
    "        if leftover and not leftover.is_empty:\n",
    "            pieces = [leftover] if isinstance(leftover, Polygon) else list(leftover.geoms)\n",
    "            for piece in pieces:\n",
    "                centroid = piece.representative_point()\n",
    "                dists = [centroid.distance(Point(lon,lat)) for _,lat,lon in open_hospitals]\n",
    "                idx = int(np.argmin(dists))\n",
    "                name = names[idx]\n",
    "                polys[name] = polys.get(name, Polygon()).union(piece)\n",
    "\n",
    "        return polys\n",
    "\n",
    "    # Fallback grid approximation: rasterize clip_geom, assign nearest hospital\n",
    "    minx, miny, maxx, maxy = clip_geom.bounds\n",
    "    # build a modest grid (~300m resolution) to keep runtime reasonable\n",
    "    res = 0.003  # degrees ~ ~300m at mid-lat (approx)\n",
    "    xs = np.arange(minx, maxx, res)\n",
    "    ys = np.arange(miny, maxy, res)\n",
    "    grid_pts = []\n",
    "    owner = {}\n",
    "    for x in xs:\n",
    "        for y in ys:\n",
    "            pt = Point(x,y)\n",
    "            if not pt.within(clip_geom):\n",
    "                continue\n",
    "            # find nearest\n",
    "            dmin = 1e9\n",
    "            idx = None\n",
    "            for i, (_, lat, lon) in enumerate(open_hospitals):\n",
    "                d = (lat - y)**2 + (lon - x)**2\n",
    "                if d < dmin:\n",
    "                    dmin = d\n",
    "                    idx = i\n",
    "            owner.setdefault(idx, []).append(pt)\n",
    "    polys = {}\n",
    "    for i, pts in owner.items():\n",
    "        mp = unary_union([p.buffer(res*0.7) for p in pts]).buffer(0)\n",
    "        poly = mp.intersection(clip_geom)\n",
    "        if not poly.is_empty:\n",
    "            polys[names[i]] = poly\n",
    "    return polys\n",
    "\n",
    "# function to compute area_km2 from polygon using projected area\n",
    "def area_km2(poly):\n",
    "    if poly.is_empty:\n",
    "        return 0.0\n",
    "    geod_gdf = gpd.GeoSeries([poly], crs='EPSG:4326').to_crs('EPSG:3857')\n",
    "    area_m2 = geod_gdf.iloc[0].area\n",
    "    return float(area_m2) / 1e6\n",
    "\n",
    "# Process function for one segment: build voronoi for open hospitals, count attacks\n",
    "from collections import defaultdict\n",
    "\n",
    "def process_segment(seg_start, seg_end, focus_hospital_name=None):\n",
    "    open_hosps = get_open_hospitals_for_period(hosp_df, name_col, lat_col, lon_col, timelines_from_excel, seg_start, seg_end)\n",
    "    print(f'Open hospitals during {seg_start} to {seg_end}: {[h[0] for h in open_hosps]}')\n",
    "    polys = build_voronoi_polygons(open_hosps, gaza_union)\n",
    "\n",
    "    # filter ACLED events in segment\n",
    "    mask = (ac['_date'] >= seg_start) & (ac['_date'] <= seg_end)\n",
    "    events_seg = ac[mask].copy()\n",
    "    events_seg['geometry'] = events_seg.apply(lambda r: Point(r['_lon'], r['_lat']), axis=1)\n",
    "    events_gdf = gpd.GeoDataFrame(events_seg, geometry='geometry', crs='EPSG:4326')\n",
    "\n",
    "    # count attacks per hospital polygon\n",
    "    counts = defaultdict(int)\n",
    "    events_assigned = []\n",
    "    for hosp_name, poly in polys.items():\n",
    "        if poly.is_empty:\n",
    "            continue\n",
    "        within = events_gdf[events_gdf.within(poly)]\n",
    "        counts[hosp_name] = len(within)\n",
    "        events_assigned.append((hosp_name, within))\n",
    "\n",
    "    # collect areas\n",
    "    areas = {h: area_km2(polys[h]) for h in polys}\n",
    "\n",
    "    return {'polys': polys, 'areas': areas, 'counts': dict(counts), 'events_assigned': events_assigned, 'open_hospitals': open_hosps}\n",
    "\n",
    "# --- Generate Al Nasser first two-week map ---\n",
    "nasser_start, nasser_end = hosp_interest_periods['Nasser Hospital']\n",
    "# first segment\n",
    "nasser_seg_start, nasser_seg_end = list(two_week_segments(nasser_start, nasser_end))[0]\n",
    "print('\\nBuilding Al Nasser first segment map for', nasser_seg_start, 'to', nasser_seg_end)\n",
    "res_nasser = process_segment(nasser_seg_start, nasser_seg_end, focus_hospital_name='Nasser Hospital')\n",
    "\n",
    "# Save Excel summary for three hospitals (all their segments)\n",
    "rows = []\n",
    "for hosp_name, (start_dt, end_dt) in hosp_interest_periods.items():\n",
    "    for seg_start, seg_end in two_week_segments(start_dt, end_dt):\n",
    "        r = process_segment(seg_start, seg_end)\n",
    "        area = r['areas'].get(hosp_name, 0.0)\n",
    "        attacks = r['counts'].get(hosp_name, 0)\n",
    "        total_attacks = len(ac[(ac['_date'] >= seg_start) & (ac['_date'] <= seg_end)])\n",
    "        pct = (attacks / total_attacks * 100) if total_attacks>0 else 0.0\n",
    "        rows.append({\n",
    "            'Hospital': hosp_name,\n",
    "            'Segment Start': seg_start,\n",
    "            'Segment End': seg_end,\n",
    "            'Open Hospitals': ', '.join([h[0] for h in r['open_hospitals']]),\n",
    "            'Catchment Area (km2)': round(area,2),\n",
    "            'Attacks in Catchment': attacks,\n",
    "            'Total Attacks in Segment': total_attacks,\n",
    "            'Percent of Attacks': round(pct,2)\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(rows)\n",
    "out_file = base / 'perc_attacks_incatchmentareas_recomputed.xlsx'\n",
    "df_summary.to_excel(out_file, index=False)\n",
    "print('\\nSaved results to', out_file.name)\n",
    "\n",
    "# Build and save Folium map for Al Nasser first segment\n",
    "m = folium.Map(location=[31.9,35.2], zoom_start=11)\n",
    "# add Gaza outline\n",
    "folium.GeoJson(gaza.__geo_interface__, name='Gaza boundary', style_function=lambda x: {'fill':False,'color':'black','weight':2}).add_to(m)\n",
    "\n",
    "# colors\n",
    "color_map = ['#e41a1c','#377eb8','#4daf4a','#984ea3','#ff7f00']\n",
    "for i,(hname, lat, lon) in enumerate(res_nasser['open_hospitals']):\n",
    "    c = color_map[i % len(color_map)]\n",
    "    poly = res_nasser['polys'].get(hname)\n",
    "    if poly is None:\n",
    "        continue\n",
    "    # handle multipolygon\n",
    "    if isinstance(poly, MultiPolygon):\n",
    "        polys_iter = poly.geoms\n",
    "    else:\n",
    "        polys_iter = [poly]\n",
    "    for p in polys_iter:\n",
    "        coords = [[pt[1], pt[0]] for pt in list(p.exterior.coords)]\n",
    "        folium.Polygon(locations=coords, color=c, fill=True, fillOpacity=0.3, popup=f\"{hname}: {res_nasser['areas'].get(hname,0):.2f} km2 | attacks: {res_nasser['counts'].get(hname,0)}\").add_to(m)\n",
    "    folium.CircleMarker(location=[lat,lon], radius=6, color=c, fill=True, fillColor=c, popup=hname).add_to(m)\n",
    "\n",
    "# add attack points that were assigned to Nasser Hospital in this segment (if any)\n",
    "nasser_events = [ev for name, ev in res_nasser['events_assigned'] if name == 'Nasser Hospital']\n",
    "if nasser_events:\n",
    "    events_gdf = nasser_events[0]\n",
    "    for _, row in events_gdf.iterrows():\n",
    "        folium.CircleMarker(location=[row['_lat'], row['_lon']], radius=3, color='black', fill=True, fillColor='red').add_to(m)\n",
    "\n",
    "map_out = base / 'catchment_visualization_Nasser_first_segment.html'\n",
    "m.save(str(map_out))\n",
    "print('Saved Al Nasser first-segment map to', map_out.name)\n",
    "\n",
    "# display summary head\n",
    "print('\\nSummary (first 10 rows):')\n",
    "display(df_summary.head(10))\n",
    "\n",
    "print('\\nDone.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
